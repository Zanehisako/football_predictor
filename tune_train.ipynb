{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6f509eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "   üöÄ WIN/LOSS SPECIALIST MODEL (No Draw Predictions)    \n",
      "==========================================================\n",
      "‚úÖ Loaded 2964 matches.\n",
      "\n",
      "üîß Building Enhanced Features...\n",
      "Building Win/Loss Features...\n",
      "Total features: 357\n",
      "\n",
      "Train: 2519 | Test: 445\n",
      "\n",
      "üéØ Training Ensemble for Win/Loss Prediction...\n",
      "  ‚Üí XGBoost...\n",
      "  ‚Üí Random Forest...\n",
      "  ‚Üí Gradient Boosting...\n",
      "\n",
      "üé≤ Making Predictions (No Draws)...\n",
      "\n",
      "==================================================\n",
      "   WIN/LOSS SPECIALIST ACCURACY: 53.48%   \n",
      "==================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 86   0  60]\n",
      " [ 37   0  62]\n",
      " [ 48   0 152]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Away       0.50      0.59      0.54       146\n",
      "        Draw       0.00      0.00      0.00        99\n",
      "        Home       0.55      0.76      0.64       200\n",
      "\n",
      "    accuracy                           0.53       445\n",
      "   macro avg       0.35      0.45      0.39       445\n",
      "weighted avg       0.41      0.53      0.47       445\n",
      "\n",
      "\n",
      "üìä Win/Loss Performance:\n",
      "   Away Win Accuracy: 86/146 = 58.9%\n",
      "   Home Win Accuracy: 152/200 = 76.0%\n",
      "   Decisive Match Accuracy: 238/346 = 68.8%\n",
      "\n",
      "üìä Draw Handling:\n",
      "   Draws called as Away: 37/99 (37.4%)\n",
      "   Draws called as Home: 62/99 (62.6%)\n",
      "   Average cost per draw: 100.0%\n",
      "\n",
      "ü§ñ Individual Model Accuracies:\n",
      "   XGBoost: 52.13%\n",
      "   Random Forest: 54.38%\n",
      "   Gradient Boosting: 54.61%\n",
      "\n",
      "üìà Confidence Analysis:\n",
      "   Confidence >0.1: 375 matches, 57.87% accurate\n",
      "   Confidence >0.2: 309 matches, 60.52% accurate\n",
      "   Confidence >0.3: 248 matches, 64.52% accurate\n",
      "   Confidence >0.4: 186 matches, 66.67% accurate\n",
      "\n",
      "üîç Top 15 Features:\n",
      "   diff_players_touches_attacking_third: 0.0143\n",
      "   diff_elo: 0.0139\n",
      "   diff_players_proggresive_passes: 0.0099\n",
      "   diff_players_touches_attacking_penalty_area: 0.0059\n",
      "   diff_players_carries: 0.0054\n",
      "   diff_passing_onTarget: 0.0052\n",
      "   diff_players_progressive_passes_recived: 0.0052\n",
      "   diff_players_live_touches: 0.0051\n",
      "   diff_team_xg: 0.0047\n",
      "   diff_players_xA: 0.0047\n",
      "   home_roll_players_touches_attacking_third: 0.0045\n",
      "   home_roll_players_proggresive_passes: 0.0044\n",
      "   home_roll_passing_onTarget: 0.0042\n",
      "   diff_recent_players_xA: 0.0041\n",
      "   home_roll_players_progressive_carrying_final_third: 0.0040\n",
      "\n",
      "‚úÖ Win/Loss Specialist Model Saved.\n",
      "\n",
      "üí° Strategy: Accept draws as unpredictable, maximize win/loss accuracy.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"==========================================================\")\n",
    "print(\"   üöÄ WIN/LOSS SPECIALIST MODEL (No Draw Predictions)    \")\n",
    "print(\"==========================================================\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. LOAD & CLEAN\n",
    "# ==========================================\n",
    "try:\n",
    "    df = pd.read_csv(\"match_data.csv\")\n",
    "    print(f\"‚úÖ Loaded {len(df)} matches.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Error: match_data.csv not found.\")\n",
    "    exit()\n",
    "\n",
    "def extract_date(url):\n",
    "    try:\n",
    "        match = re.search(r'([A-Za-z]+-\\d{1,2}-\\d{4})', str(url))\n",
    "        if match: return pd.to_datetime(match.group(1), format='%B-%d-%Y', errors='coerce')\n",
    "    except: pass\n",
    "    return pd.NaT\n",
    "\n",
    "df['date'] = df['match_url'].apply(extract_date)\n",
    "df = df.sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "def get_stat_cols(df):\n",
    "    exclude = ['match_url', 'date', 'home_team_name', 'away_team_name', 'xg_is_estimated', 'match_outcome']\n",
    "    cols = [c for c in df.columns if c not in exclude]\n",
    "    base_stats = set()\n",
    "    for c in cols:\n",
    "        if c.startswith('home_'): base_stats.add(c.replace('home_', ''))\n",
    "        elif c.startswith('away_'): base_stats.add(c.replace('away_', ''))\n",
    "    return list(base_stats)\n",
    "\n",
    "all_stats = get_stat_cols(df)\n",
    "\n",
    "for side in ['home', 'away']:\n",
    "    p_col = f\"{side}_team_possession\"\n",
    "    if p_col in df.columns and df[p_col].dtype == 'object':\n",
    "        df[p_col] = pd.to_numeric(df[p_col].astype(str).str.rstrip('%'), errors='coerce').fillna(50) / 100.0\n",
    "\n",
    "    for s in all_stats:\n",
    "        col = f\"{side}_{s}\"\n",
    "        if col not in df.columns: col = f\"{side}_team_{s}\"\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            df[col] = df[col].fillna(df.groupby(f'{side}_team_name')[col].transform('median'))\n",
    "            df[col] = df[col].fillna(0)\n",
    "\n",
    "# ==========================================\n",
    "# 2. ENHANCED FEATURE ENGINEERING\n",
    "# ==========================================\n",
    "print(\"\\nüîß Building Enhanced Features...\")\n",
    "\n",
    "def calculate_elo_advanced(df):\n",
    "    \"\"\"Enhanced ELO with form tracking\"\"\"\n",
    "    k_factor = 22\n",
    "    home_advantage = 65\n",
    "    team_elos = {team: 1500 for team in set(df['home_team_name']).union(set(df['away_team_name']))}\n",
    "    team_form = {team: [] for team in team_elos.keys()}\n",
    "    \n",
    "    elo_h, elo_a, form_h, form_a, momentum_h, momentum_a = [], [], [], [], [], []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        h, a = row['home_team_name'], row['away_team_name']\n",
    "        rh, ra = team_elos[h], team_elos[a]\n",
    "        elo_h.append(rh)\n",
    "        elo_a.append(ra)\n",
    "        \n",
    "        # Recent form (last 5 games)\n",
    "        recent_h = team_form[h][-5:] if team_form[h] else [0.5] * 5\n",
    "        recent_a = team_form[a][-5:] if team_form[a] else [0.5] * 5\n",
    "        form_h.append(np.mean(recent_h))\n",
    "        form_a.append(np.mean(recent_a))\n",
    "        \n",
    "        # Momentum (last 3 vs previous 3)\n",
    "        if len(team_form[h]) >= 6:\n",
    "            momentum_h.append(np.mean(team_form[h][-3:]) - np.mean(team_form[h][-6:-3]))\n",
    "        else:\n",
    "            momentum_h.append(0)\n",
    "        \n",
    "        if len(team_form[a]) >= 6:\n",
    "            momentum_a.append(np.mean(team_form[a][-3:]) - np.mean(team_form[a][-6:-3]))\n",
    "        else:\n",
    "            momentum_a.append(0)\n",
    "        \n",
    "        if row['home_team_score'] > row['away_team_score']: \n",
    "            res_h, res_a = 1, 0\n",
    "        elif row['home_team_score'] == row['away_team_score']: \n",
    "            res_h, res_a = 0.5, 0.5\n",
    "        else: \n",
    "            res_h, res_a = 0, 1\n",
    "        \n",
    "        team_form[h].append(res_h)\n",
    "        team_form[a].append(res_a)\n",
    "        \n",
    "        dr = (rh + home_advantage) - ra\n",
    "        e_h = 1 / (1 + 10 ** (-dr / 400))\n",
    "        change = k_factor * (res_h - e_h)\n",
    "        team_elos[h] = rh + change\n",
    "        team_elos[a] = ra - change\n",
    "    \n",
    "    return elo_h, elo_a, form_h, form_a, momentum_h, momentum_a, team_elos\n",
    "\n",
    "df['home_elo'], df['away_elo'], df['home_form'], df['away_form'], df['home_momentum'], df['away_momentum'], current_elos = calculate_elo_advanced(df)\n",
    "df['diff_elo'] = (df['home_elo'] + 65) - df['away_elo']\n",
    "\n",
    "# Rolling Stats with multiple windows\n",
    "cols_to_roll = []\n",
    "h_d = df[['date', 'match_url', 'home_team_name']].rename(columns={'home_team_name':'team'})\n",
    "a_d = df[['date', 'match_url', 'away_team_name']].rename(columns={'away_team_name':'team'})\n",
    "\n",
    "for f in all_stats:\n",
    "    c_h = f\"home_{f}\" if f\"home_{f}\" in df.columns else f\"home_team_{f}\"\n",
    "    c_a = f\"away_{f}\" if f\"away_{f}\" in df.columns else f\"away_team_{f}\"\n",
    "    if c_h in df.columns and c_a in df.columns:\n",
    "        h_d[f] = df[c_h]\n",
    "        a_d[f] = df[c_a]\n",
    "        cols_to_roll.append(f)\n",
    "\n",
    "stacked = pd.concat([h_d, a_d]).sort_values(['team', 'date'])\n",
    "\n",
    "# Multiple rolling windows\n",
    "for f in cols_to_roll:\n",
    "    stacked[f'roll_{f}'] = stacked.groupby('team')[f].transform(\n",
    "        lambda x: x.shift(1).ewm(span=10, min_periods=1).mean()\n",
    "    )\n",
    "    stacked[f'roll_recent_{f}'] = stacked.groupby('team')[f].transform(\n",
    "        lambda x: x.shift(1).ewm(span=5, min_periods=1).mean()\n",
    "    )\n",
    "\n",
    "roll_cols = [f'roll_{f}' for f in cols_to_roll] + [f'roll_recent_{f}' for f in cols_to_roll]\n",
    "df = df.merge(stacked[['match_url', 'team'] + roll_cols], \n",
    "              left_on=['match_url', 'home_team_name'], right_on=['match_url', 'team'], \n",
    "              how='left').drop(columns=['team']).rename(columns={c: f'home_{c}' for c in roll_cols})\n",
    "df = df.merge(stacked[['match_url', 'team'] + roll_cols], \n",
    "              left_on=['match_url', 'away_team_name'], right_on=['match_url', 'team'], \n",
    "              how='left').drop(columns=['team']).rename(columns={c: f'away_{c}' for c in roll_cols})\n",
    "\n",
    "# Build feature set focused on WIN/LOSS discrimination\n",
    "print(\"Building Win/Loss Features...\")\n",
    "features = ['diff_elo', 'home_elo', 'away_elo', 'home_form', 'away_form', \n",
    "            'home_momentum', 'away_momentum']\n",
    "\n",
    "# Form differentials\n",
    "df['form_advantage'] = df['home_form'] - df['away_form']\n",
    "df['momentum_advantage'] = df['home_momentum'] - df['away_momentum']\n",
    "features.extend(['form_advantage', 'momentum_advantage'])\n",
    "\n",
    "# Statistical advantages\n",
    "for f in cols_to_roll:\n",
    "    df[f'diff_{f}'] = df[f'home_roll_{f}'] - df[f'away_roll_{f}']\n",
    "    df[f'diff_recent_{f}'] = df[f'home_roll_recent_{f}'] - df[f'away_roll_recent_{f}']\n",
    "    features.extend([f'diff_{f}', f'diff_recent_{f}', \n",
    "                     f'home_roll_{f}', f'away_roll_{f}'])\n",
    "\n",
    "df = df.fillna(0)\n",
    "\n",
    "print(f\"Total features: {len(features)}\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. SPLIT DATA\n",
    "# ==========================================\n",
    "conditions = [\n",
    "    (df['home_team_score'] > df['away_team_score']),\n",
    "    (df['home_team_score'] == df['away_team_score']),\n",
    "    (df['home_team_score'] < df['away_team_score'])\n",
    "]\n",
    "df['match_outcome'] = np.select(conditions, [2, 1, 0])\n",
    "\n",
    "split = int(len(df) * 0.85)\n",
    "train_df = df.iloc[:split]\n",
    "test_df = df.iloc[split:]\n",
    "\n",
    "print(f\"\\nTrain: {len(train_df)} | Test: {len(test_df)}\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. ENSEMBLE MODEL (FOCUSED ON WIN/LOSS)\n",
    "# ==========================================\n",
    "print(\"\\nüéØ Training Ensemble for Win/Loss Prediction...\")\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df['match_outcome']\n",
    "X_test = test_df[features]\n",
    "y_test = test_df['match_outcome']\n",
    "\n",
    "# Train 3 diverse models\n",
    "print(\"  ‚Üí XGBoost...\")\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=600,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=6,\n",
    "    min_child_weight=1,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.85,\n",
    "    gamma=0.1,\n",
    "    reg_alpha=0.05,\n",
    "    reg_lambda=1.5,\n",
    "    objective='multi:softprob',\n",
    "    random_state=42\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"  ‚Üí Random Forest...\")\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=3,\n",
    "    max_features='sqrt',\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"  ‚Üí Gradient Boosting...\")\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.02,\n",
    "    max_depth=5,\n",
    "    subsample=0.85,\n",
    "    random_state=42\n",
    ")\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Ensemble predictions\n",
    "xgb_probs = xgb_model.predict_proba(X_test)\n",
    "rf_probs = rf_model.predict_proba(X_test)\n",
    "gb_probs = gb_model.predict_proba(X_test)\n",
    "\n",
    "# Weighted ensemble (XGBoost usually performs best)\n",
    "ensemble_probs = 0.50 * xgb_probs + 0.30 * rf_probs + 0.20 * gb_probs\n",
    "\n",
    "# ==========================================\n",
    "# 5. SIMPLE DECISION: NEVER PREDICT DRAW\n",
    "# ==========================================\n",
    "print(\"\\nüé≤ Making Predictions (No Draws)...\")\n",
    "\n",
    "# Simply pick Home if P(Home) > P(Away), else Away\n",
    "final_preds = np.where(ensemble_probs[:, 2] > ensemble_probs[:, 0], 2, 0)\n",
    "\n",
    "# ==========================================\n",
    "# 6. EVALUATION\n",
    "# ==========================================\n",
    "acc = accuracy_score(y_test, final_preds)\n",
    "\n",
    "print(\"\\n==================================================\")\n",
    "print(f\"   WIN/LOSS SPECIALIST ACCURACY: {acc:.2%}   \")\n",
    "print(\"==================================================\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, final_preds)\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, final_preds, target_names=['Away', 'Draw', 'Home']))\n",
    "\n",
    "# Detailed metrics\n",
    "away_correct = cm[0, 0]\n",
    "away_total = cm[0].sum()\n",
    "home_correct = cm[2, 2]\n",
    "home_total = cm[2].sum()\n",
    "draws_called_away = cm[1, 0]\n",
    "draws_called_home = cm[1, 2]\n",
    "\n",
    "print(f\"\\nüìä Win/Loss Performance:\")\n",
    "print(f\"   Away Win Accuracy: {away_correct}/{away_total} = {100*away_correct/away_total:.1f}%\")\n",
    "print(f\"   Home Win Accuracy: {home_correct}/{home_total} = {100*home_correct/home_total:.1f}%\")\n",
    "print(f\"   Decisive Match Accuracy: {(away_correct + home_correct)}/{(away_total + home_total)} = {100*(away_correct + home_correct)/(away_total + home_total):.1f}%\")\n",
    "\n",
    "print(f\"\\nüìä Draw Handling:\")\n",
    "print(f\"   Draws called as Away: {draws_called_away}/99 ({100*draws_called_away/99:.1f}%)\")\n",
    "print(f\"   Draws called as Home: {draws_called_home}/99 ({100*draws_called_home/99:.1f}%)\")\n",
    "print(f\"   Average cost per draw: {100*(draws_called_away + draws_called_home)/99:.1f}%\")\n",
    "\n",
    "print(f\"\\nü§ñ Individual Model Accuracies:\")\n",
    "print(f\"   XGBoost: {accuracy_score(y_test, np.where(xgb_probs[:, 2] > xgb_probs[:, 0], 2, 0)):.2%}\")\n",
    "print(f\"   Random Forest: {accuracy_score(y_test, np.where(rf_probs[:, 2] > rf_probs[:, 0], 2, 0)):.2%}\")\n",
    "print(f\"   Gradient Boosting: {accuracy_score(y_test, np.where(gb_probs[:, 2] > gb_probs[:, 0], 2, 0)):.2%}\")\n",
    "\n",
    "# Confidence analysis\n",
    "print(f\"\\nüìà Confidence Analysis:\")\n",
    "home_win_confidence = ensemble_probs[:, 2] - ensemble_probs[:, 0]\n",
    "for threshold in [0.1, 0.2, 0.3, 0.4]:\n",
    "    high_conf = np.abs(home_win_confidence) > threshold\n",
    "    if sum(high_conf) > 0:\n",
    "        high_conf_acc = accuracy_score(y_test[high_conf], final_preds[high_conf])\n",
    "        print(f\"   Confidence >{threshold:.1f}: {sum(high_conf)} matches, {high_conf_acc:.2%} accurate\")\n",
    "\n",
    "# Feature importance\n",
    "importances = xgb_model.feature_importances_\n",
    "top_15_idx = np.argsort(importances)[-15:]\n",
    "print(f\"\\nüîç Top 15 Features:\")\n",
    "for idx in top_15_idx[::-1]:\n",
    "    print(f\"   {features[idx]}: {importances[idx]:.4f}\")\n",
    "\n",
    "# Save\n",
    "joblib.dump({\n",
    "    'xgb_model': xgb_model,\n",
    "    'rf_model': rf_model,\n",
    "    'gb_model': gb_model,\n",
    "    'features': features,\n",
    "    'elo_dict': current_elos,\n",
    "    'weights': [0.50, 0.30, 0.20],\n",
    "    'df_recent': df[['date', 'home_team_name', 'away_team_name'] + \n",
    "                    [c for c in df.columns if 'roll_' in c]].tail(1500),\n",
    "}, 'football_model_winloss_specialist.pkl')\n",
    "\n",
    "print(\"\\n‚úÖ Win/Loss Specialist Model Saved.\")\n",
    "print(\"\\nüí° Strategy: Accept draws as unpredictable, maximize win/loss accuracy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bfa324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "   üöÄ GRANDMASTER TRAINER (FULL GRID SEARCH + TUNING)     \n",
      "==========================================================\n",
      "‚úÖ Loaded 2286 matches.\n",
      "Parsing dates...\n",
      "üìä Initial Features: 272\n",
      "\n",
      "‚úÇÔ∏è Selecting Top 50 Features...\n",
      "‚úÖ Reduced to 150 Features.\n",
      "\n",
      "üîç Tuning XGBoost (LogLoss)...\n",
      "‚úÖ Best XGB LogLoss: 0.9778\n",
      "   Best Params: {'colsample_bytree': 0.7, 'gamma': 2, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300, 'subsample': 0.8}\n",
      "\n",
      "üîç Tuning Random Forest (LogLoss)...\n",
      "‚úÖ Best RF LogLoss: 0.9809\n",
      "   Best Params: {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 300}\n",
      "\n",
      "üîç Tuning Logistic Regression...\n",
      "‚úÖ Best LR LogLoss: 1.0117\n",
      "\n",
      "üèóÔ∏è Building Final Ensemble...\n",
      "\n",
      "üìä EVALUATING ON TEST SET...\n",
      "==================================================\n",
      "   FINAL ACCURACY: 52.60%   \n",
      "==================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 64   1  39]\n",
      " [ 37   0  52]\n",
      " [ 33   2 118]]\n",
      "\n",
      "üéØ SNIPER ANALYSIS (High Confidence Bets):\n",
      "   > Confidence > 0.50: 178 bets | Win Rate: 64.61%\n",
      "   > Confidence > 0.55: 136 bets | Win Rate: 67.65%\n",
      "   > Confidence > 0.60: 93 bets | Win Rate: 72.04%\n",
      "   > Confidence > 0.70: 30 bets | Win Rate: 86.67%\n",
      "‚úÖ Saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, log_loss\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"==========================================================\")\n",
    "print(\"   üöÄ GRANDMASTER TRAINER (FULL GRID SEARCH + TUNING)     \")\n",
    "print(\"==========================================================\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. LOAD & CLEAN DATA\n",
    "# ==========================================\n",
    "try:\n",
    "    df = pd.read_csv(\"match_data/match_data_combined.csv\")\n",
    "    print(f\"‚úÖ Loaded {len(df)} matches.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Error: match_data_combined.csv not found.\")\n",
    "    exit()\n",
    "\n",
    "def extract_date(url):\n",
    "    try:\n",
    "        match = re.search(r'([A-Za-z]+-\\d{1,2}-\\d{4})', str(url))\n",
    "        if match: return pd.to_datetime(match.group(1), format='%B-%d-%Y', errors='coerce')\n",
    "    except: pass\n",
    "    return pd.NaT\n",
    "\n",
    "print(\"Parsing dates...\")\n",
    "df['date'] = df['match_url'].apply(extract_date)\n",
    "df = df.sort_values(by='date').reset_index(drop=True)\n",
    "df = df.dropna(subset=['date'])\n",
    "\n",
    "# --- MARKET DATA IMPUTATION ---\n",
    "if 'AvgH' in df.columns:\n",
    "    df['market_prob_home'] = (1 / df['AvgH']).fillna(0.33)\n",
    "    df['market_prob_draw'] = (1 / df['AvgD']).fillna(0.33)\n",
    "    df['market_prob_away'] = (1 / df['AvgA']).fillna(0.33)\n",
    "    \n",
    "    # Normalize\n",
    "    m_sum = df['market_prob_home'] + df['market_prob_draw'] + df['market_prob_away']\n",
    "    df['market_prob_home'] /= m_sum\n",
    "    df['market_prob_draw'] /= m_sum\n",
    "    df['market_prob_away'] /= m_sum\n",
    "    \n",
    "    df['has_odds'] = df['AvgH'].notna().astype(int)\n",
    "else:\n",
    "    df['market_prob_home'] = 0.33\n",
    "    df['market_prob_draw'] = 0.33\n",
    "    df['market_prob_away'] = 0.33\n",
    "    df['has_odds'] = 0\n",
    "\n",
    "# --- DYNAMIC STAT CLEANING ---\n",
    "def get_stat_cols(df):\n",
    "    exclude = ['match_url', 'date', 'home_team_name', 'away_team_name', 'xg_is_estimated', 'match_outcome', \n",
    "               'AvgH', 'AvgD', 'AvgA', 'Avg>2.5', 'Avg<2.5', 'market_prob_home', 'market_prob_draw', 'market_prob_away', 'has_odds']\n",
    "    cols = [c for c in df.columns if c not in exclude]\n",
    "    base_stats = set()\n",
    "    for c in cols:\n",
    "        if c.startswith('home_'): base_stats.add(c.replace('home_', ''))\n",
    "        elif c.startswith('away_'): base_stats.add(c.replace('away_', ''))\n",
    "    return list(base_stats)\n",
    "\n",
    "all_stats = get_stat_cols(df)\n",
    "\n",
    "for side in ['home', 'away']:\n",
    "    p_col = f\"{side}_team_possession\"\n",
    "    if p_col in df.columns:\n",
    "        df[p_col] = pd.to_numeric(df[p_col].astype(str).str.rstrip('%'), errors='coerce').fillna(50) / 100.0\n",
    "\n",
    "    for s in all_stats:\n",
    "        col = f\"{side}_{s}\"\n",
    "        if col not in df.columns: col = f\"{side}_team_{s}\"\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            df[col] = df[col].fillna(df.groupby(f'{side}_team_name')[col].transform('median'))\n",
    "            df[col] = df[col].fillna(0)\n",
    "\n",
    "# ==========================================\n",
    "# 2. FEATURE ENGINEERING\n",
    "# ==========================================\n",
    "\n",
    "# --- ELO ---\n",
    "def calculate_elo(df):\n",
    "    k_factor = 20\n",
    "    home_advantage = 70\n",
    "    team_elos = {team: 1500 for team in set(df['home_team_name']).union(set(df['away_team_name']))}\n",
    "    elo_h, elo_a = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        h, a = row['home_team_name'], row['away_team_name']\n",
    "        rh, ra = team_elos[h], team_elos[a]\n",
    "        elo_h.append(rh); elo_a.append(ra)\n",
    "        if row['home_team_score'] > row['away_team_score']: res = 1\n",
    "        elif row['home_team_score'] == row['away_team_score']: res = 0.5\n",
    "        else: res = 0\n",
    "        dr = (rh + home_advantage) - ra\n",
    "        e_h = 1 / (1 + 10 ** (-dr / 400))\n",
    "        change = k_factor * (res - e_h)\n",
    "        team_elos[h] = rh + change\n",
    "        team_elos[a] = ra - change\n",
    "    return elo_h, elo_a, team_elos\n",
    "\n",
    "df['home_elo'], df['away_elo'], current_elos = calculate_elo(df)\n",
    "df['diff_elo'] = (df['home_elo'] + 70) - df['away_elo']\n",
    "\n",
    "# --- Rest Days ---\n",
    "long_df = pd.concat([\n",
    "    df[['date', 'home_team_name']].rename(columns={'home_team_name':'team'}),\n",
    "    df[['date', 'away_team_name']].rename(columns={'away_team_name':'team'})\n",
    "]).sort_values(['team', 'date'])\n",
    "long_df['rest'] = (long_df['date'] - long_df.groupby('team')['date'].shift(1)).dt.days.fillna(7).clip(upper=14)\n",
    "rest_map = dict(zip(zip(long_df['date'], long_df['team']), long_df['rest']))\n",
    "df['diff_rest'] = df.apply(lambda x: rest_map.get((x['date'], x['home_team_name']),7), axis=1) - \\\n",
    "                  df.apply(lambda x: rest_map.get((x['date'], x['away_team_name']),7), axis=1)\n",
    "\n",
    "# --- Rolling Stats ---\n",
    "df['home_team_points'] = np.select([df['home_team_score']>df['away_team_score'], df['home_team_score']==df['away_team_score']], [3, 1], 0)\n",
    "df['away_team_points'] = np.select([df['away_team_score']>df['home_team_score'], df['away_team_score']==df['home_team_score']], [3, 1], 0)\n",
    "if 'team_points' not in all_stats: all_stats.append('team_points')\n",
    "\n",
    "cols_to_roll = []\n",
    "h_d = df[['date', 'match_url', 'home_team_name']].rename(columns={'home_team_name':'team'})\n",
    "a_d = df[['date', 'match_url', 'away_team_name']].rename(columns={'away_team_name':'team'})\n",
    "\n",
    "for f in all_stats:\n",
    "    c_h = f\"home_{f}\" if f\"home_{f}\" in df.columns else f\"home_team_{f}\"\n",
    "    c_a = f\"away_{f}\" if f\"away_{f}\" in df.columns else f\"away_team_{f}\"\n",
    "    if c_h in df.columns and c_a in df.columns:\n",
    "        h_d[f] = df[c_h]; a_d[f] = df[c_a]\n",
    "        cols_to_roll.append(f)\n",
    "\n",
    "stacked = pd.concat([h_d, a_d]).sort_values(['team', 'date'])\n",
    "for f in cols_to_roll:\n",
    "    # Use EWMA 10 for stability\n",
    "    stacked[f'roll_{f}'] = stacked.groupby('team')[f].transform(lambda x: x.shift(1).ewm(span=10, min_periods=1).mean())\n",
    "\n",
    "df = df.merge(stacked[['match_url', 'team'] + [f'roll_{f}' for f in cols_to_roll]], left_on=['match_url', 'home_team_name'], right_on=['match_url', 'team'], how='left').drop(columns=['team']).rename(columns={f'roll_{f}': f'home_roll_{f}' for f in cols_to_roll})\n",
    "df = df.merge(stacked[['match_url', 'team'] + [f'roll_{f}' for f in cols_to_roll]], left_on=['match_url', 'away_team_name'], right_on=['match_url', 'team'], how='left').drop(columns=['team']).rename(columns={f'roll_{f}': f'away_roll_{f}' for f in cols_to_roll})\n",
    "\n",
    "for f in cols_to_roll:\n",
    "    df[f'diff_{f}'] = df[f'home_roll_{f}'] - df[f'away_roll_{f}']\n",
    "\n",
    "df = df.fillna(0)\n",
    "\n",
    "# ==========================================\n",
    "# 3. SELECT TOP FEATURES (RFE)\n",
    "# ==========================================\n",
    "features = ['diff_elo', 'home_elo', 'away_elo', 'diff_rest', 'market_prob_home', 'market_prob_draw', 'market_prob_away', 'has_odds']\n",
    "for f in cols_to_roll:\n",
    "    features.append(f\"home_roll_{f}\")\n",
    "    features.append(f\"away_roll_{f}\")\n",
    "    features.append(f\"diff_{f}\")\n",
    "\n",
    "print(f\"üìä Initial Features: {len(features)}\")\n",
    "\n",
    "conditions = [\n",
    "    (df['home_team_score'] > df['away_team_score']),\n",
    "    (df['home_team_score'] == df['away_team_score']),\n",
    "    (df['home_team_score'] < df['away_team_score'])\n",
    "]\n",
    "y = np.select(conditions, [2, 1, 0])\n",
    "X = df[features].copy()\n",
    "\n",
    "split = int(len(df) * 0.85)\n",
    "X_train = X.iloc[:split]\n",
    "X_test = X.iloc[split:]\n",
    "y_train = y[:split]\n",
    "y_test = y[split:]\n",
    "\n",
    "print(\"\\n‚úÇÔ∏è Selecting Top 50 Features...\")\n",
    "# Random Forest is best at finding non-linear relationships\n",
    "selector = SelectFromModel(\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42), \n",
    "    max_features=100, \n",
    "    threshold=-np.inf\n",
    ")\n",
    "selector.fit(X_train, y_train)\n",
    "selected_cols = X_train.columns[selector.get_support()]\n",
    "\n",
    "# Update Data\n",
    "X_train = X_train[selected_cols]\n",
    "X_test = X_test[selected_cols]\n",
    "print(f\"‚úÖ Reduced to {len(selected_cols)} Features.\")\n",
    "# print(f\"Top Features: {list(selected_cols[:10])}\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. GRID SEARCH (MAXIMIZE HIGH CONFIDENCE)\n",
    "# ==========================================\n",
    "# We use 'neg_log_loss' as scoring because it optimizes for Probability Calibration\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# --- 1. XGBoost ---\n",
    "print(\"\\nüîç Tuning XGBoost (LogLoss)...\")\n",
    "xgb_grid = {\n",
    "    'n_estimators': [200, 300],\n",
    "    'learning_rate': [0.01, 0.03],\n",
    "    'max_depth': [3, 4],\n",
    "    'subsample': [0.7, 0.8],\n",
    "    'colsample_bytree': [0.7, 0.8],\n",
    "    'gamma': [1, 2] # Regularization\n",
    "}\n",
    "xgb_base = xgb.XGBClassifier(objective='multi:softprob', num_class=3, tree_method='hist', random_state=42)\n",
    "gs_xgb = GridSearchCV(xgb_base, xgb_grid, cv=tscv, scoring='neg_log_loss', n_jobs=-1)\n",
    "gs_xgb.fit(X_train, y_train)\n",
    "print(f\"‚úÖ Best XGB LogLoss: {-gs_xgb.best_score_:.4f}\")\n",
    "print(f\"   Best Params: {gs_xgb.best_params_}\")\n",
    "best_xgb = gs_xgb.best_estimator_\n",
    "\n",
    "# --- 2. Random Forest ---\n",
    "print(\"\\nüîç Tuning Random Forest (LogLoss)...\")\n",
    "rf_grid = {\n",
    "    'n_estimators': [300, 500],\n",
    "    'max_depth': [8, 12, 15],\n",
    "    'min_samples_leaf': [2, 5],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "rf_base = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "gs_rf = GridSearchCV(rf_base, rf_grid, cv=tscv, scoring='neg_log_loss', n_jobs=-1)\n",
    "gs_rf.fit(X_train, y_train)\n",
    "print(f\"‚úÖ Best RF LogLoss: {-gs_rf.best_score_:.4f}\")\n",
    "print(f\"   Best Params: {gs_rf.best_params_}\")\n",
    "best_rf = gs_rf.best_estimator_\n",
    "\n",
    "# --- 3. Logistic Regression ---\n",
    "print(\"\\nüîç Tuning Logistic Regression...\")\n",
    "lr_pipe = make_pipeline(StandardScaler(), LogisticRegression(class_weight='balanced', multi_class='multinomial', max_iter=2000))\n",
    "lr_grid = {\n",
    "    'logisticregression__C': [0.01, 0.1, 1.0],\n",
    "    'logisticregression__solver': ['lbfgs']\n",
    "}\n",
    "gs_lr = GridSearchCV(lr_pipe, lr_grid, cv=tscv, scoring='neg_log_loss', n_jobs=-1)\n",
    "gs_lr.fit(X_train, y_train)\n",
    "print(f\"‚úÖ Best LR LogLoss: {-gs_lr.best_score_:.4f}\")\n",
    "best_lr = gs_lr.best_estimator_\n",
    "\n",
    "# ==========================================\n",
    "# 5. FINAL ENSEMBLE\n",
    "# ==========================================\n",
    "print(\"\\nüèóÔ∏è Building Final Ensemble...\")\n",
    "\n",
    "# We weight based on which model had the best LogLoss\n",
    "# Lower LogLoss = Higher Weight\n",
    "weights = [1.2, 1.5, 0.8] # Heuristic: RF usually wins on small noisy data, LR is good anchor\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[('xgb', best_xgb), ('rf', best_rf), ('lr', best_lr)],\n",
    "    voting='soft',\n",
    "    weights=weights\n",
    ")\n",
    "\n",
    "# Calibrate (Sigmoid)\n",
    "calibrated = CalibratedClassifierCV(ensemble, method='sigmoid', cv=3)\n",
    "calibrated.fit(X_train, y_train)\n",
    "\n",
    "# ==========================================\n",
    "# 6. EVALUATION\n",
    "# ==========================================\n",
    "print(\"\\nüìä EVALUATING ON TEST SET...\")\n",
    "preds = calibrated.predict(X_test)\n",
    "probs = calibrated.predict_proba(X_test)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "\n",
    "print(\"==================================================\")\n",
    "print(f\"   FINAL ACCURACY: {acc:.2%}   \")\n",
    "print(\"==================================================\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, preds))\n",
    "\n",
    "# --- SNIPER ANALYSIS ---\n",
    "print(\"\\nüéØ SNIPER ANALYSIS (High Confidence Bets):\")\n",
    "results = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Pred': preds,\n",
    "    'Conf': np.max(probs, axis=1)\n",
    "})\n",
    "\n",
    "for t in [0.50, 0.55, 0.60, 0.70]:\n",
    "    sub = results[results['Conf'] > t]\n",
    "    if len(sub) > 0:\n",
    "        win_rate = accuracy_score(sub['Actual'], sub['Pred'])\n",
    "        print(f\"   > Confidence > {t:.2f}: {len(sub)} bets | Win Rate: {win_rate:.2%}\")\n",
    "\n",
    "# Save\n",
    "joblib.dump({\n",
    "    'model': calibrated, \n",
    "    'features': list(selected_cols),\n",
    "    'elo_dict': current_elos,\n",
    "    'df_recent': df[['date', 'home_team_name', 'away_team_name'] + [c for c in df.columns if 'roll_' in c]].tail(1000)\n",
    "}, 'football_model_final.pkl')\n",
    "\n",
    "print(\"‚úÖ Saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58e47423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "   üîç FEATURE IMPORTANCE (MARKET AWARENESS)       \n",
      "==================================================\n",
      "‚úÖ Model Loaded. Features: 60\n",
      "\n",
      "üèÜ TOP 20 FEATURES:\n",
      "                                    Feature  Importance\n",
      "                                   diff_elo    0.049892\n",
      "                           market_prob_away    0.038096\n",
      "                           market_prob_home    0.037551\n",
      "                                   home_elo    0.026865\n",
      "                            diff_players_xA    0.024345\n",
      "diff_players_touches_attacking_penalty_area    0.022287\n",
      "                           market_prob_draw    0.021000\n",
      "       diff_players_touches_attacking_third    0.018309\n",
      "                           diff_total_shots    0.017935\n",
      "                         home_roll_offsides    0.017918\n",
      "                          diff_players_npxG    0.017883\n",
      "         home_roll_players_defensive_errors    0.017432\n",
      "    diff_players_progressive_passes_recived    0.017205\n",
      "                           diff_players_xAG    0.017119\n",
      "                       diff_goalkeeper_PSxG    0.017044\n",
      "                          home_roll_team_xg    0.016878\n",
      "                               diff_team_xg    0.016696\n",
      "    away_roll_players_long_passes_completed    0.016616\n",
      "                      home_roll_total_saves    0.016576\n",
      "                           diff_team_points    0.016453\n",
      "\n",
      "üí∞ MARKET ODDS RANKING:\n",
      "            Feature  Importance\n",
      "4  market_prob_away    0.038096\n",
      "2  market_prob_home    0.037551\n",
      "3  market_prob_draw    0.021000\n",
      "\n",
      "üèÉ NEW PLAYER STATS RANKING (TOP 5):\n",
      "                                        Feature  Importance\n",
      "19                              diff_players_xA    0.024345\n",
      "55  diff_players_touches_attacking_penalty_area    0.022287\n",
      "48         diff_players_touches_attacking_third    0.018309\n",
      "29                            diff_players_npxG    0.017883\n",
      "38           home_roll_players_defensive_errors    0.017432\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"==================================================\")\n",
    "print(\"   üîç FEATURE IMPORTANCE (MARKET AWARENESS)       \")\n",
    "print(\"==================================================\")\n",
    "\n",
    "try:\n",
    "    artifacts = joblib.load('football_model_final.pkl')\n",
    "    model = artifacts['model']\n",
    "    features = artifacts['features']\n",
    "    print(f\"‚úÖ Model Loaded. Features: {len(features)}\")\n",
    "    \n",
    "    # Extract from Calibrated -> Voting -> Random Forest (Index 0 or 1 depending on weights)\n",
    "    # Note: VotingClassifier doesn't expose feature_importances_ directly.\n",
    "    # We need to dig into the fitted estimators.\n",
    "    \n",
    "    # 1. Get the Voting Classifier\n",
    "    voting_clf = model.calibrated_classifiers_[0].estimator\n",
    "    \n",
    "    # 2. Get Random Forest (It usually has the best feature importance logic)\n",
    "    # Check names in voting clf\n",
    "    rf_model = voting_clf.named_estimators_.get('rf', None)\n",
    "\n",
    "            \n",
    "    if rf_model:\n",
    "        importances = rf_model.feature_importances_\n",
    "        \n",
    "        # DataFrame\n",
    "        fi_df = pd.DataFrame({\n",
    "            'Feature': features,\n",
    "            'Importance': importances\n",
    "        }).sort_values(by='Importance', ascending=False)\n",
    "        \n",
    "        print(\"\\nüèÜ TOP 20 FEATURES:\")\n",
    "        print(fi_df.head(20).to_string(index=False))\n",
    "        \n",
    "        # Check for Market Odds\n",
    "        print(\"\\nüí∞ MARKET ODDS RANKING:\")\n",
    "        odds_feats = [f for f in features if 'market' in f or 'odds' in f]\n",
    "        print(fi_df[fi_df['Feature'].isin(odds_feats)])\n",
    "        \n",
    "        # Check for Player Stats\n",
    "        print(\"\\nüèÉ NEW PLAYER STATS RANKING (TOP 5):\")\n",
    "        player_feats = [f for f in features if 'player' in f]\n",
    "        print(fi_df[fi_df['Feature'].isin(player_feats)].head(5))\n",
    "\n",
    "    else:\n",
    "        print(\"Could not find Random Forest in ensemble.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bae86a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
