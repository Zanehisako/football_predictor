{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f509eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "   HYPERPARAMETER TUNING ENGINE (ELO + ENSEMBLE)  \n",
      "==================================================\n",
      "Generating Smart Form (EWMA)...\n",
      "Tuning on 1272 matches...\n",
      "\n",
      "--- Tuning XGBoost ---\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "✅ Best XGB Params: {'colsample_bytree': 0.8, 'gamma': 1, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100, 'subsample': 0.7}\n",
      "✅ Best XGB Score: 51.60%\n",
      "\n",
      "--- Tuning Random Forest ---\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "✅ Best RF Params: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'n_estimators': 400}\n",
      "✅ Best RF Score: 49.34%\n",
      "\n",
      "--- Tuning Logistic Regression ---\n",
      "✅ Best LR Params: {'C': 0.01, 'solver': 'lbfgs'}\n",
      "✅ Best LR Score: 49.81%\n",
      "Training Stacking Ensemble (The Supervisor)...\n",
      "✅ Smart Ensemble Trained & Calibrated.\n",
      "==================================================\n",
      "   CALIBRATED ACCURACY: 63.14%   \n",
      "==================================================\n",
      "Sample Probabilities (First 5 matches):\n",
      "[[0.09973734 0.34912205 0.55114061]\n",
      " [0.46309597 0.19801065 0.33889338]\n",
      " [0.57251035 0.22114087 0.20634878]\n",
      " [0.14946671 0.1353177  0.71521558]\n",
      " [0.18539342 0.12912574 0.68548085]]\n",
      "Threshold > 0.45: 202 matches | Accuracy: 71.29%\n",
      "Threshold > 0.50: 155 matches | Accuracy: 74.84%\n",
      "Threshold > 0.60: 82 matches | Accuracy: 92.68%\n",
      "Threshold > 0.70: 47 matches | Accuracy: 100.00%\n",
      "Threshold > 0.80: 14 matches | Accuracy: 100.00%\n",
      "✅ Calibrated Model saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import re\n",
    "import warnings\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"==================================================\")\n",
    "print(\"   HYPERPARAMETER TUNING ENGINE (ELO + ENSEMBLE)  \")\n",
    "print(\"==================================================\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. LOAD & CLEAN (Same Feature Engineering)\n",
    "# ==========================================\n",
    "# We must recreate the exact features (ELO, Rolling, Rest) first\n",
    "df = pd.read_csv(\"match_data.csv\")\n",
    "\n",
    "def extract_date(url):\n",
    "    try:\n",
    "        match = re.search(r'([A-Za-z]+-\\d{1,2}-\\d{4})', str(url))\n",
    "        if match: return pd.to_datetime(match.group(1), format='%B-%d-%Y', errors='coerce')\n",
    "    except: pass\n",
    "    return pd.NaT\n",
    "\n",
    "df['date'] = df['match_url'].apply(extract_date)\n",
    "df = df.sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "# Basic Numeric Cleaning & Imputation\n",
    "stats_cols = [\"xg\", \"possession\", \"shots_onTarget\", \"corners\", \"fouls\", \"team_points\"]\n",
    "for side in ['home', 'away']:\n",
    "    p_col = f\"{side}_team_possession\"\n",
    "    if p_col in df.columns:\n",
    "        df[p_col] = pd.to_numeric(df[p_col].astype(str).str.rstrip('%'), errors='coerce').fillna(50) / 100.0\n",
    "    \n",
    "    # Calculate points if missing (3 for win logic)\n",
    "    if 'team_points' not in df.columns and f'{side}_team_score' in df.columns:\n",
    "        # (Logic handled in rolling block below)\n",
    "        pass\n",
    "\n",
    "    for s in stats_cols:\n",
    "        col = f\"{side}_{s}\" if s not in ['xg', 'possession', 'team_points'] else f\"{side}_team_{s}\"\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            # Group median fill\n",
    "            df[col] = df[col].fillna(df.groupby(f'{side}_team_name')[col].transform('median'))\n",
    "            df[col] = df[col].fillna(df[col].mean()) # Fallback\n",
    "\n",
    "# --- ELO CALCULATION ---\n",
    "def calculate_elo(df):\n",
    "    k_factor = 20          # Standard K-Factor (Stable)\n",
    "    home_advantage = 60   # You found this works best for PL\n",
    "    \n",
    "    # Initialize all teams at 1500\n",
    "    team_elos = {team: 1500 for team in set(df['home_team_name']).union(set(df['away_team_name']))}\n",
    "    elo_h, elo_a = [], []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        h, a = row['home_team_name'], row['away_team_name']\n",
    "        rh, ra = team_elos[h], team_elos[a]\n",
    "        \n",
    "        # Store ratings BEFORE the match (Predictive)\n",
    "        elo_h.append(rh); elo_a.append(ra)\n",
    "        \n",
    "        # Result (1, 0.5, 0)\n",
    "        if row['home_team_score'] > row['away_team_score']: res = 1\n",
    "        elif row['home_team_score'] == row['away_team_score']: res = 0.5\n",
    "        else: res = 0\n",
    "        \n",
    "        # Expected Result\n",
    "        # No \"Goal Difference\" multiplier here. \n",
    "        # This keeps ratings tighter and improves Draw predictions.\n",
    "        dr = (rh + home_advantage) - ra\n",
    "        e_h = 1 / (1 + 10 ** (-dr / 400))\n",
    "        \n",
    "        # Update\n",
    "        change = k_factor * (res - e_h)\n",
    "        team_elos[h] = rh + change\n",
    "        team_elos[a] = ra - change\n",
    "        \n",
    "    return elo_h, elo_a \n",
    "\n",
    "df['home_elo'], df['away_elo'] = calculate_elo(df)\n",
    "df['diff_elo'] = (df['home_elo'] + 65) - df['away_elo']\n",
    "\n",
    "# --- REST DAYS ---\n",
    "def calc_rest(df):\n",
    "    long_df = pd.concat([\n",
    "        df[['date', 'home_team_name']].rename(columns={'home_team_name':'team'}),\n",
    "        df[['date', 'away_team_name']].rename(columns={'away_team_name':'team'})\n",
    "    ]).sort_values(['team', 'date'])\n",
    "    long_df['rest'] = (long_df['date'] - long_df.groupby('team')['date'].shift(1)).dt.days.fillna(7).clip(upper=14)\n",
    "    return dict(zip(zip(long_df['date'], long_df['team']), long_df['rest']))\n",
    "\n",
    "rest_map = calc_rest(df)\n",
    "df['diff_rest'] = df.apply(lambda x: rest_map.get((x['date'], x['home_team_name']),7), axis=1) - \\\n",
    "                  df.apply(lambda x: rest_map.get((x['date'], x['away_team_name']),7), axis=1)\n",
    "\n",
    "# ==========================================\n",
    "# 2. ROLLING AVERAGES ENGINE (UPGRADED TO EWMA)\n",
    "# ==========================================\n",
    "print(\"Generating Smart Form (EWMA)...\")\n",
    "\n",
    "# Recalculate Points for Form\n",
    "df['home_team_points'] = np.select([df['home_team_score']>df['away_team_score'], df['home_team_score']==df['away_team_score']], [3, 1], 0)\n",
    "df['away_team_points'] = np.select([df['away_team_score']>df['home_team_score'], df['away_team_score']==df['home_team_score']], [3, 1], 0)\n",
    "\n",
    "# Add 'team_score' (Goals) to calculate Efficiency later\n",
    "roll_feats = ['team_xg', 'team_possession', 'shots_onTarget', 'corners', 'team_points', 'fouls', 'team_score']\n",
    "\n",
    "h_d = df[['date', 'match_url', 'home_team_name']].rename(columns={'home_team_name':'team'})\n",
    "a_d = df[['date', 'match_url', 'away_team_name']].rename(columns={'away_team_name':'team'})\n",
    "\n",
    "for f in roll_feats:\n",
    "    c_h = f\"home_{f}\" if f in ['team_points', 'team_xg', 'team_possession', 'team_score'] else f\"home_{f}\"\n",
    "    c_a = f\"away_{f}\" if f in ['team_points', 'team_xg', 'team_possession', 'team_score'] else f\"away_{f}\"\n",
    "    if c_h in df.columns: h_d[f] = df[c_h]\n",
    "    if c_a in df.columns: a_d[f] = df[c_a]\n",
    "\n",
    "stacked = pd.concat([h_d, a_d]).sort_values(['team', 'date'])\n",
    "\n",
    "for f in roll_feats:\n",
    "    if f in stacked.columns:\n",
    "        # --- THE SMART CHANGE: EWM (Exponential Weighted Mean) ---\n",
    "        # span=5 means the last 5 games matter, but the most recent one counts for ~33% of the weight\n",
    "        stacked[f'roll_{f}'] = stacked.groupby('team')[f].transform(lambda x: x.shift(1).ewm(span=5, min_periods=1).mean())\n",
    "\n",
    "df = df.merge(stacked[['match_url', 'team'] + [f'roll_{f}' for f in roll_feats]], left_on=['match_url', 'home_team_name'], right_on=['match_url', 'team'], how='left').drop(columns=['team']).rename(columns={f'roll_{f}': f'home_roll_{f}' for f in roll_feats})\n",
    "df = df.merge(stacked[['match_url', 'team'] + [f'roll_{f}' for f in roll_feats]], left_on=['match_url', 'away_team_name'], right_on=['match_url', 'team'], how='left').drop(columns=['team']).rename(columns={f'roll_{f}': f'away_roll_{f}' for f in roll_feats})\n",
    "\n",
    "# Calculate Differentials for rest\n",
    "for f in roll_feats:\n",
    "    df[f'diff_{f}'] = df[f'home_roll_{f}'] - df[f'away_roll_{f}']\n",
    "\n",
    "df = df.fillna(0)\n",
    "\n",
    "# ==========================================\n",
    "# 2. PREPARE FOR TUNING\n",
    "# ==========================================\n",
    "conditions = [\n",
    "    (df['home_team_score'] > df['away_team_score']),\n",
    "    (df['home_team_score'] == df['away_team_score']),\n",
    "    (df['home_team_score'] < df['away_team_score'])\n",
    "]\n",
    "df['match_outcome'] = np.select(conditions, [2, 1, 0])\n",
    "\n",
    "features = [\n",
    "    'diff_elo', 'home_elo', 'away_elo',\n",
    "    'diff_rest', 'diff_team_points', 'diff_team_xg', \n",
    "    'diff_shots_onTarget', 'diff_corners',\n",
    "    'home_roll_team_xg', 'away_roll_team_xg',\n",
    "    'home_roll_team_possession', 'away_roll_team_possession',\n",
    "    'home_roll_shots_onTarget', 'away_roll_shots_onTarget',\n",
    "    'home_roll_corners', 'away_roll_corners',\n",
    "    'home_roll_fouls', 'away_roll_fouls',\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df['match_outcome']\n",
    "split = int(len(df) * 0.8)\n",
    "\n",
    "X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]\n",
    "\n",
    "# Time Series Split (Crucial for validity)\n",
    "# 4 splits = Test on last 20%, then last 40%, etc.\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "print(f\"Tuning on {len(X)} matches...\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. TUNE XGBOOST\n",
    "# ==========================================\n",
    "print(\"\\n--- Tuning XGBoost ---\")\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.03, 0.05],\n",
    "    'max_depth': [4, 5],\n",
    "    'subsample': [0.7, 0.8],\n",
    "    'colsample_bytree': [0.7, 0.8],\n",
    "    'gamma': [1] # Regularization\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softprob', num_class=3, tree_method='hist', random_state=42)\n",
    "xgb_search = GridSearchCV(xgb_model, xgb_param_grid, cv=tscv, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "xgb_search.fit(X, y)\n",
    "\n",
    "print(f\"✅ Best XGB Params: {xgb_search.best_params_}\")\n",
    "print(f\"✅ Best XGB Score: {xgb_search.best_score_:.2%}\")\n",
    "best_xgb = xgb_search.best_estimator_\n",
    "\n",
    "# ==========================================\n",
    "# 4. TUNE RANDOM FOREST\n",
    "# ==========================================\n",
    "print(\"\\n--- Tuning Random Forest ---\")\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [200, 400],\n",
    "    'max_depth': [5, 8, 10,12], # Keep shallow to prevent overfitting noise\n",
    "    'min_samples_leaf': [3, 5, 10], # Higher = more generalized\n",
    "    'max_features': ['sqrt', 0.5]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42,class_weight='balanced')\n",
    "rf_search = GridSearchCV(rf_model, rf_param_grid, cv=tscv, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "rf_search.fit(X, y)\n",
    "\n",
    "print(f\"✅ Best RF Params: {rf_search.best_params_}\")\n",
    "print(f\"✅ Best RF Score: {rf_search.best_score_:.2%}\")\n",
    "best_rf = rf_search.best_estimator_\n",
    "\n",
    "# ==========================================\n",
    "# 5. TUNE LOGISTIC REGRESSION\n",
    "# ==========================================\n",
    "print(\"\\n--- Tuning Logistic Regression ---\")\n",
    "lr_param_grid = {\n",
    "    'C': [0.01, 0.1, 1.0, 10.0], # Regularization strength\n",
    "    'solver': ['lbfgs', 'newton-cg']\n",
    "}\n",
    "\n",
    "scaler = StandardScaler() # LR needs scaled data\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "lr_model = LogisticRegression(multi_class='multinomial', max_iter=10000,class_weight='balanced')\n",
    "lr_search = GridSearchCV(lr_model, lr_param_grid, cv=tscv, scoring='accuracy', n_jobs=-1)\n",
    "lr_search.fit(X_scaled, y)\n",
    "\n",
    "print(f\"✅ Best LR Params: {lr_search.best_params_}\")\n",
    "print(f\"✅ Best LR Score: {lr_search.best_score_:.2%}\")\n",
    "best_lr = lr_search.best_estimator_\n",
    "\n",
    "\n",
    "# --- 4. The Ensemble (UPGRADED TO STACKING) ---\n",
    "print(\"Training Stacking Ensemble (The Supervisor)...\")\n",
    "\n",
    "# The \"Final Estimator\" decides how to mix the models based on their outputs.\n",
    "# Logistic Regression is excellent for this \"Arbitration\" role.\n",
    "stacking_ensemble = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', best_xgb),\n",
    "        ('rf', best_rf),\n",
    "        ('lr', best_lr)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=5, # Internal Cross-Validation to train the supervisor without leakage\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Note: We wrap this in Calibration just like before\n",
    "calibrated_stack = CalibratedClassifierCV(\n",
    "    estimator=stacking_ensemble,\n",
    "    method='isotonic',\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "calibrated_stack.fit(X, y)\n",
    "print(\"✅ Smart Ensemble Trained & Calibrated.\")\n",
    "\n",
    "# Update the variable name for saving\n",
    "calibrated_ensemble = calibrated_stack\n",
    "\n",
    "# ==========================================\n",
    "# 7. FINAL EVALUATION\n",
    "# ==========================================\n",
    "preds = calibrated_ensemble.predict(X_test)\n",
    "probs = calibrated_ensemble.predict_proba(X_test)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "\n",
    "print(\"==================================================\")\n",
    "print(f\"   CALIBRATED ACCURACY: {acc:.2%}   \")\n",
    "print(\"==================================================\")\n",
    "\n",
    "# Check the new Probabilities\n",
    "print(\"Sample Probabilities (First 5 matches):\")\n",
    "print(probs[:5])\n",
    "\n",
    "# Value Bets Check\n",
    "results = pd.DataFrame({\n",
    "    'Home': df.iloc[split:]['home_team_name'],\n",
    "    'Away': df.iloc[split:]['away_team_name'],\n",
    "    'Actual': y_test.values,\n",
    "    'Pred': preds,\n",
    "    'Conf': np.max(probs, axis=1)\n",
    "})\n",
    "\n",
    "for t in [0.45, 0.50, 0.60, 0.70, 0.80]:\n",
    "    sub = results[results['Conf'] > t]\n",
    "    if len(sub) > 0:\n",
    "        print(f\"Threshold > {t:.2f}: {len(sub)} matches | Accuracy: {accuracy_score(sub['Actual'], sub['Pred']):.2%}\")\n",
    "\n",
    "# Save the CALIBRATED model\n",
    "joblib.dump({\n",
    "    'model': calibrated_ensemble, \n",
    "    'features': features,\n",
    "    'elo_dict': dict(zip(df['home_team_name'], df['home_elo'])),\n",
    "    'df_recent': df[['date', 'home_team_name', 'away_team_name'] + [c for c in df.columns if 'roll_' in c]].tail(1000)\n",
    "}, 'football_model_final.pkl')\n",
    "\n",
    "print(\"✅ Calibrated Model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c038fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55  0 29]\n",
      " [10  7 30]\n",
      " [25  0 99]]\n",
      "Accuracy: 63.14%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "print(cm)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, preds):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4272f50e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
