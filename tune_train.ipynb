{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6f509eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "   üöÄ WIN/LOSS SPECIALIST MODEL (No Draw Predictions)    \n",
      "==========================================================\n",
      "‚úÖ Loaded 2964 matches.\n",
      "\n",
      "üîß Building Enhanced Features...\n",
      "Building Win/Loss Features...\n",
      "Total features: 357\n",
      "\n",
      "Train: 2519 | Test: 445\n",
      "\n",
      "üéØ Training Ensemble for Win/Loss Prediction...\n",
      "  ‚Üí XGBoost...\n",
      "  ‚Üí Random Forest...\n",
      "  ‚Üí Gradient Boosting...\n",
      "\n",
      "üé≤ Making Predictions (No Draws)...\n",
      "\n",
      "==================================================\n",
      "   WIN/LOSS SPECIALIST ACCURACY: 53.48%   \n",
      "==================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 86   0  60]\n",
      " [ 37   0  62]\n",
      " [ 48   0 152]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Away       0.50      0.59      0.54       146\n",
      "        Draw       0.00      0.00      0.00        99\n",
      "        Home       0.55      0.76      0.64       200\n",
      "\n",
      "    accuracy                           0.53       445\n",
      "   macro avg       0.35      0.45      0.39       445\n",
      "weighted avg       0.41      0.53      0.47       445\n",
      "\n",
      "\n",
      "üìä Win/Loss Performance:\n",
      "   Away Win Accuracy: 86/146 = 58.9%\n",
      "   Home Win Accuracy: 152/200 = 76.0%\n",
      "   Decisive Match Accuracy: 238/346 = 68.8%\n",
      "\n",
      "üìä Draw Handling:\n",
      "   Draws called as Away: 37/99 (37.4%)\n",
      "   Draws called as Home: 62/99 (62.6%)\n",
      "   Average cost per draw: 100.0%\n",
      "\n",
      "ü§ñ Individual Model Accuracies:\n",
      "   XGBoost: 52.13%\n",
      "   Random Forest: 54.38%\n",
      "   Gradient Boosting: 54.61%\n",
      "\n",
      "üìà Confidence Analysis:\n",
      "   Confidence >0.1: 375 matches, 57.87% accurate\n",
      "   Confidence >0.2: 309 matches, 60.52% accurate\n",
      "   Confidence >0.3: 248 matches, 64.52% accurate\n",
      "   Confidence >0.4: 186 matches, 66.67% accurate\n",
      "\n",
      "üîç Top 15 Features:\n",
      "   diff_players_touches_attacking_third: 0.0143\n",
      "   diff_elo: 0.0139\n",
      "   diff_players_proggresive_passes: 0.0099\n",
      "   diff_players_touches_attacking_penalty_area: 0.0059\n",
      "   diff_players_carries: 0.0054\n",
      "   diff_passing_onTarget: 0.0052\n",
      "   diff_players_progressive_passes_recived: 0.0052\n",
      "   diff_players_live_touches: 0.0051\n",
      "   diff_team_xg: 0.0047\n",
      "   diff_players_xA: 0.0047\n",
      "   home_roll_players_touches_attacking_third: 0.0045\n",
      "   home_roll_players_proggresive_passes: 0.0044\n",
      "   home_roll_passing_onTarget: 0.0042\n",
      "   diff_recent_players_xA: 0.0041\n",
      "   home_roll_players_progressive_carrying_final_third: 0.0040\n",
      "\n",
      "‚úÖ Win/Loss Specialist Model Saved.\n",
      "\n",
      "üí° Strategy: Accept draws as unpredictable, maximize win/loss accuracy.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"==========================================================\")\n",
    "print(\"   üöÄ WIN/LOSS SPECIALIST MODEL (No Draw Predictions)    \")\n",
    "print(\"==========================================================\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. LOAD & CLEAN\n",
    "# ==========================================\n",
    "try:\n",
    "    df = pd.read_csv(\"match_data.csv\")\n",
    "    print(f\"‚úÖ Loaded {len(df)} matches.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Error: match_data.csv not found.\")\n",
    "    exit()\n",
    "\n",
    "def extract_date(url):\n",
    "    try:\n",
    "        match = re.search(r'([A-Za-z]+-\\d{1,2}-\\d{4})', str(url))\n",
    "        if match: return pd.to_datetime(match.group(1), format='%B-%d-%Y', errors='coerce')\n",
    "    except: pass\n",
    "    return pd.NaT\n",
    "\n",
    "df['date'] = df['match_url'].apply(extract_date)\n",
    "df = df.sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "def get_stat_cols(df):\n",
    "    exclude = ['match_url', 'date', 'home_team_name', 'away_team_name', 'xg_is_estimated', 'match_outcome']\n",
    "    cols = [c for c in df.columns if c not in exclude]\n",
    "    base_stats = set()\n",
    "    for c in cols:\n",
    "        if c.startswith('home_'): base_stats.add(c.replace('home_', ''))\n",
    "        elif c.startswith('away_'): base_stats.add(c.replace('away_', ''))\n",
    "    return list(base_stats)\n",
    "\n",
    "all_stats = get_stat_cols(df)\n",
    "\n",
    "for side in ['home', 'away']:\n",
    "    p_col = f\"{side}_team_possession\"\n",
    "    if p_col in df.columns and df[p_col].dtype == 'object':\n",
    "        df[p_col] = pd.to_numeric(df[p_col].astype(str).str.rstrip('%'), errors='coerce').fillna(50) / 100.0\n",
    "\n",
    "    for s in all_stats:\n",
    "        col = f\"{side}_{s}\"\n",
    "        if col not in df.columns: col = f\"{side}_team_{s}\"\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            df[col] = df[col].fillna(df.groupby(f'{side}_team_name')[col].transform('median'))\n",
    "            df[col] = df[col].fillna(0)\n",
    "\n",
    "# ==========================================\n",
    "# 2. ENHANCED FEATURE ENGINEERING\n",
    "# ==========================================\n",
    "print(\"\\nüîß Building Enhanced Features...\")\n",
    "\n",
    "def calculate_elo_advanced(df):\n",
    "    \"\"\"Enhanced ELO with form tracking\"\"\"\n",
    "    k_factor = 22\n",
    "    home_advantage = 65\n",
    "    team_elos = {team: 1500 for team in set(df['home_team_name']).union(set(df['away_team_name']))}\n",
    "    team_form = {team: [] for team in team_elos.keys()}\n",
    "    \n",
    "    elo_h, elo_a, form_h, form_a, momentum_h, momentum_a = [], [], [], [], [], []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        h, a = row['home_team_name'], row['away_team_name']\n",
    "        rh, ra = team_elos[h], team_elos[a]\n",
    "        elo_h.append(rh)\n",
    "        elo_a.append(ra)\n",
    "        \n",
    "        # Recent form (last 5 games)\n",
    "        recent_h = team_form[h][-5:] if team_form[h] else [0.5] * 5\n",
    "        recent_a = team_form[a][-5:] if team_form[a] else [0.5] * 5\n",
    "        form_h.append(np.mean(recent_h))\n",
    "        form_a.append(np.mean(recent_a))\n",
    "        \n",
    "        # Momentum (last 3 vs previous 3)\n",
    "        if len(team_form[h]) >= 6:\n",
    "            momentum_h.append(np.mean(team_form[h][-3:]) - np.mean(team_form[h][-6:-3]))\n",
    "        else:\n",
    "            momentum_h.append(0)\n",
    "        \n",
    "        if len(team_form[a]) >= 6:\n",
    "            momentum_a.append(np.mean(team_form[a][-3:]) - np.mean(team_form[a][-6:-3]))\n",
    "        else:\n",
    "            momentum_a.append(0)\n",
    "        \n",
    "        if row['home_team_score'] > row['away_team_score']: \n",
    "            res_h, res_a = 1, 0\n",
    "        elif row['home_team_score'] == row['away_team_score']: \n",
    "            res_h, res_a = 0.5, 0.5\n",
    "        else: \n",
    "            res_h, res_a = 0, 1\n",
    "        \n",
    "        team_form[h].append(res_h)\n",
    "        team_form[a].append(res_a)\n",
    "        \n",
    "        dr = (rh + home_advantage) - ra\n",
    "        e_h = 1 / (1 + 10 ** (-dr / 400))\n",
    "        change = k_factor * (res_h - e_h)\n",
    "        team_elos[h] = rh + change\n",
    "        team_elos[a] = ra - change\n",
    "    \n",
    "    return elo_h, elo_a, form_h, form_a, momentum_h, momentum_a, team_elos\n",
    "\n",
    "df['home_elo'], df['away_elo'], df['home_form'], df['away_form'], df['home_momentum'], df['away_momentum'], current_elos = calculate_elo_advanced(df)\n",
    "df['diff_elo'] = (df['home_elo'] + 65) - df['away_elo']\n",
    "\n",
    "# Rolling Stats with multiple windows\n",
    "cols_to_roll = []\n",
    "h_d = df[['date', 'match_url', 'home_team_name']].rename(columns={'home_team_name':'team'})\n",
    "a_d = df[['date', 'match_url', 'away_team_name']].rename(columns={'away_team_name':'team'})\n",
    "\n",
    "for f in all_stats:\n",
    "    c_h = f\"home_{f}\" if f\"home_{f}\" in df.columns else f\"home_team_{f}\"\n",
    "    c_a = f\"away_{f}\" if f\"away_{f}\" in df.columns else f\"away_team_{f}\"\n",
    "    if c_h in df.columns and c_a in df.columns:\n",
    "        h_d[f] = df[c_h]\n",
    "        a_d[f] = df[c_a]\n",
    "        cols_to_roll.append(f)\n",
    "\n",
    "stacked = pd.concat([h_d, a_d]).sort_values(['team', 'date'])\n",
    "\n",
    "# Multiple rolling windows\n",
    "for f in cols_to_roll:\n",
    "    stacked[f'roll_{f}'] = stacked.groupby('team')[f].transform(\n",
    "        lambda x: x.shift(1).ewm(span=10, min_periods=1).mean()\n",
    "    )\n",
    "    stacked[f'roll_recent_{f}'] = stacked.groupby('team')[f].transform(\n",
    "        lambda x: x.shift(1).ewm(span=5, min_periods=1).mean()\n",
    "    )\n",
    "\n",
    "roll_cols = [f'roll_{f}' for f in cols_to_roll] + [f'roll_recent_{f}' for f in cols_to_roll]\n",
    "df = df.merge(stacked[['match_url', 'team'] + roll_cols], \n",
    "              left_on=['match_url', 'home_team_name'], right_on=['match_url', 'team'], \n",
    "              how='left').drop(columns=['team']).rename(columns={c: f'home_{c}' for c in roll_cols})\n",
    "df = df.merge(stacked[['match_url', 'team'] + roll_cols], \n",
    "              left_on=['match_url', 'away_team_name'], right_on=['match_url', 'team'], \n",
    "              how='left').drop(columns=['team']).rename(columns={c: f'away_{c}' for c in roll_cols})\n",
    "\n",
    "# Build feature set focused on WIN/LOSS discrimination\n",
    "print(\"Building Win/Loss Features...\")\n",
    "features = ['diff_elo', 'home_elo', 'away_elo', 'home_form', 'away_form', \n",
    "            'home_momentum', 'away_momentum']\n",
    "\n",
    "# Form differentials\n",
    "df['form_advantage'] = df['home_form'] - df['away_form']\n",
    "df['momentum_advantage'] = df['home_momentum'] - df['away_momentum']\n",
    "features.extend(['form_advantage', 'momentum_advantage'])\n",
    "\n",
    "# Statistical advantages\n",
    "for f in cols_to_roll:\n",
    "    df[f'diff_{f}'] = df[f'home_roll_{f}'] - df[f'away_roll_{f}']\n",
    "    df[f'diff_recent_{f}'] = df[f'home_roll_recent_{f}'] - df[f'away_roll_recent_{f}']\n",
    "    features.extend([f'diff_{f}', f'diff_recent_{f}', \n",
    "                     f'home_roll_{f}', f'away_roll_{f}'])\n",
    "\n",
    "df = df.fillna(0)\n",
    "\n",
    "print(f\"Total features: {len(features)}\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. SPLIT DATA\n",
    "# ==========================================\n",
    "conditions = [\n",
    "    (df['home_team_score'] > df['away_team_score']),\n",
    "    (df['home_team_score'] == df['away_team_score']),\n",
    "    (df['home_team_score'] < df['away_team_score'])\n",
    "]\n",
    "df['match_outcome'] = np.select(conditions, [2, 1, 0])\n",
    "\n",
    "split = int(len(df) * 0.85)\n",
    "train_df = df.iloc[:split]\n",
    "test_df = df.iloc[split:]\n",
    "\n",
    "print(f\"\\nTrain: {len(train_df)} | Test: {len(test_df)}\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. ENSEMBLE MODEL (FOCUSED ON WIN/LOSS)\n",
    "# ==========================================\n",
    "print(\"\\nüéØ Training Ensemble for Win/Loss Prediction...\")\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df['match_outcome']\n",
    "X_test = test_df[features]\n",
    "y_test = test_df['match_outcome']\n",
    "\n",
    "# Train 3 diverse models\n",
    "print(\"  ‚Üí XGBoost...\")\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=600,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=6,\n",
    "    min_child_weight=1,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.85,\n",
    "    gamma=0.1,\n",
    "    reg_alpha=0.05,\n",
    "    reg_lambda=1.5,\n",
    "    objective='multi:softprob',\n",
    "    random_state=42\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"  ‚Üí Random Forest...\")\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=3,\n",
    "    max_features='sqrt',\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"  ‚Üí Gradient Boosting...\")\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.02,\n",
    "    max_depth=5,\n",
    "    subsample=0.85,\n",
    "    random_state=42\n",
    ")\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Ensemble predictions\n",
    "xgb_probs = xgb_model.predict_proba(X_test)\n",
    "rf_probs = rf_model.predict_proba(X_test)\n",
    "gb_probs = gb_model.predict_proba(X_test)\n",
    "\n",
    "# Weighted ensemble (XGBoost usually performs best)\n",
    "ensemble_probs = 0.50 * xgb_probs + 0.30 * rf_probs + 0.20 * gb_probs\n",
    "\n",
    "# ==========================================\n",
    "# 5. SIMPLE DECISION: NEVER PREDICT DRAW\n",
    "# ==========================================\n",
    "print(\"\\nüé≤ Making Predictions (No Draws)...\")\n",
    "\n",
    "# Simply pick Home if P(Home) > P(Away), else Away\n",
    "final_preds = np.where(ensemble_probs[:, 2] > ensemble_probs[:, 0], 2, 0)\n",
    "\n",
    "# ==========================================\n",
    "# 6. EVALUATION\n",
    "# ==========================================\n",
    "acc = accuracy_score(y_test, final_preds)\n",
    "\n",
    "print(\"\\n==================================================\")\n",
    "print(f\"   WIN/LOSS SPECIALIST ACCURACY: {acc:.2%}   \")\n",
    "print(\"==================================================\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, final_preds)\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, final_preds, target_names=['Away', 'Draw', 'Home']))\n",
    "\n",
    "# Detailed metrics\n",
    "away_correct = cm[0, 0]\n",
    "away_total = cm[0].sum()\n",
    "home_correct = cm[2, 2]\n",
    "home_total = cm[2].sum()\n",
    "draws_called_away = cm[1, 0]\n",
    "draws_called_home = cm[1, 2]\n",
    "\n",
    "print(f\"\\nüìä Win/Loss Performance:\")\n",
    "print(f\"   Away Win Accuracy: {away_correct}/{away_total} = {100*away_correct/away_total:.1f}%\")\n",
    "print(f\"   Home Win Accuracy: {home_correct}/{home_total} = {100*home_correct/home_total:.1f}%\")\n",
    "print(f\"   Decisive Match Accuracy: {(away_correct + home_correct)}/{(away_total + home_total)} = {100*(away_correct + home_correct)/(away_total + home_total):.1f}%\")\n",
    "\n",
    "print(f\"\\nüìä Draw Handling:\")\n",
    "print(f\"   Draws called as Away: {draws_called_away}/99 ({100*draws_called_away/99:.1f}%)\")\n",
    "print(f\"   Draws called as Home: {draws_called_home}/99 ({100*draws_called_home/99:.1f}%)\")\n",
    "print(f\"   Average cost per draw: {100*(draws_called_away + draws_called_home)/99:.1f}%\")\n",
    "\n",
    "print(f\"\\nü§ñ Individual Model Accuracies:\")\n",
    "print(f\"   XGBoost: {accuracy_score(y_test, np.where(xgb_probs[:, 2] > xgb_probs[:, 0], 2, 0)):.2%}\")\n",
    "print(f\"   Random Forest: {accuracy_score(y_test, np.where(rf_probs[:, 2] > rf_probs[:, 0], 2, 0)):.2%}\")\n",
    "print(f\"   Gradient Boosting: {accuracy_score(y_test, np.where(gb_probs[:, 2] > gb_probs[:, 0], 2, 0)):.2%}\")\n",
    "\n",
    "# Confidence analysis\n",
    "print(f\"\\nüìà Confidence Analysis:\")\n",
    "home_win_confidence = ensemble_probs[:, 2] - ensemble_probs[:, 0]\n",
    "for threshold in [0.1, 0.2, 0.3, 0.4]:\n",
    "    high_conf = np.abs(home_win_confidence) > threshold\n",
    "    if sum(high_conf) > 0:\n",
    "        high_conf_acc = accuracy_score(y_test[high_conf], final_preds[high_conf])\n",
    "        print(f\"   Confidence >{threshold:.1f}: {sum(high_conf)} matches, {high_conf_acc:.2%} accurate\")\n",
    "\n",
    "# Feature importance\n",
    "importances = xgb_model.feature_importances_\n",
    "top_15_idx = np.argsort(importances)[-15:]\n",
    "print(f\"\\nüîç Top 15 Features:\")\n",
    "for idx in top_15_idx[::-1]:\n",
    "    print(f\"   {features[idx]}: {importances[idx]:.4f}\")\n",
    "\n",
    "# Save\n",
    "joblib.dump({\n",
    "    'xgb_model': xgb_model,\n",
    "    'rf_model': rf_model,\n",
    "    'gb_model': gb_model,\n",
    "    'features': features,\n",
    "    'elo_dict': current_elos,\n",
    "    'weights': [0.50, 0.30, 0.20],\n",
    "    'df_recent': df[['date', 'home_team_name', 'away_team_name'] + \n",
    "                    [c for c in df.columns if 'roll_' in c]].tail(1500),\n",
    "}, 'football_model_winloss_specialist.pkl')\n",
    "\n",
    "print(\"\\n‚úÖ Win/Loss Specialist Model Saved.\")\n",
    "print(\"\\nüí° Strategy: Accept draws as unpredictable, maximize win/loss accuracy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42bfa324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "   üöÄ ULTIMATE TRAINER v2 (ODDS + ALL PLAYER STATS)       \n",
      "==========================================================\n",
      "‚úÖ Loaded 2286 matches.\n",
      "Processing Market Odds...\n",
      "üîç Detected 88 unique stats (Team + Player).\n",
      "Scrubbing data for artifacts (2*, %, etc)...\n",
      "Generating Rolling Stats for ALL features...\n",
      "üìä Total Available Features: 271\n",
      "\n",
      "‚úÇÔ∏è Selecting Top 60 Features (RFECV/ModelBased)...\n",
      "‚úÖ Reduced to 60 Features.\n",
      "Augmented Train Size: 2444\n",
      "\n",
      "üèóÔ∏è Building Voting Ensemble...\n",
      "‚öñÔ∏è Calibrating (Sigmoid)...\n",
      "\n",
      "üìä EVALUATING...\n",
      "==================================================\n",
      "   FINAL ACCURACY: 51.73%   \n",
      "==================================================\n",
      "[[62 15 27]\n",
      " [31 22 36]\n",
      " [32 26 95]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Away       0.50      0.60      0.54       104\n",
      "        Draw       0.35      0.25      0.29        89\n",
      "        Home       0.60      0.62      0.61       153\n",
      "\n",
      "    accuracy                           0.52       346\n",
      "   macro avg       0.48      0.49      0.48       346\n",
      "weighted avg       0.50      0.52      0.51       346\n",
      "\n",
      "‚úÖ Model Saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"==========================================================\")\n",
    "print(\"   üöÄ ULTIMATE TRAINER v2 (ODDS + ALL PLAYER STATS)       \")\n",
    "print(\"==========================================================\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. LOAD & CLEAN\n",
    "# ==========================================\n",
    "try:\n",
    "    df = pd.read_csv(\"match_data_combined.csv\")\n",
    "    print(f\"‚úÖ Loaded {len(df)} matches.\")\n",
    "except:\n",
    "    print(\"‚ùå Error: match_data_combined.csv not found.\")\n",
    "    exit()\n",
    "\n",
    "def extract_date(url):\n",
    "    try:\n",
    "        match = re.search(r'([A-Za-z]+-\\d{1,2}-\\d{4})', str(url))\n",
    "        if match: return pd.to_datetime(match.group(1), format='%B-%d-%Y', errors='coerce')\n",
    "    except: pass\n",
    "    return pd.NaT\n",
    "\n",
    "df['date'] = df['match_url'].apply(extract_date)\n",
    "df = df.sort_values(by='date').reset_index(drop=True)\n",
    "df = df.dropna(subset=['date'])\n",
    "\n",
    "# --- 1.1 ODDS PROCESSING ---\n",
    "print(\"Processing Market Odds...\")\n",
    "if 'AvgH' in df.columns:\n",
    "    df['market_prob_home'] = (1 / df['AvgH']).fillna(0.33)\n",
    "    df['market_prob_draw'] = (1 / df['AvgD']).fillna(0.33)\n",
    "    df['market_prob_away'] = (1 / df['AvgA']).fillna(0.33)\n",
    "    \n",
    "    # Normalize\n",
    "    m_sum = df['market_prob_home'] + df['market_prob_draw'] + df['market_prob_away']\n",
    "    df['market_prob_home'] /= m_sum\n",
    "    df['market_prob_draw'] /= m_sum\n",
    "    df['market_prob_away'] /= m_sum\n",
    "    \n",
    "    df['has_odds'] = df['AvgH'].notna().astype(int)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No Odds Columns Found! Using dummies.\")\n",
    "    df['market_prob_home'] = 0.33\n",
    "    df['market_prob_draw'] = 0.33\n",
    "    df['market_prob_away'] = 0.33\n",
    "    df['has_odds'] = 0\n",
    "\n",
    "# --- 1.2 DYNAMIC FEATURE IDENTIFICATION ---\n",
    "# Identify ALL stat columns (including player stats)\n",
    "def get_stat_cols(df):\n",
    "    exclude = ['match_url', 'date', 'home_team_name', 'away_team_name', 'xg_is_estimated', 'match_outcome', \n",
    "               'AvgH', 'AvgD', 'AvgA', 'Avg>2.5', 'Avg<2.5', 'market_prob_home', 'market_prob_draw', 'market_prob_away', 'has_odds']\n",
    "    cols = [c for c in df.columns if c not in exclude]\n",
    "    \n",
    "    base_stats = set()\n",
    "    for c in cols:\n",
    "        if c.startswith('home_'): base_stats.add(c.replace('home_', ''))\n",
    "        elif c.startswith('away_'): base_stats.add(c.replace('away_', ''))\n",
    "            \n",
    "    return list(base_stats)\n",
    "\n",
    "all_stats = get_stat_cols(df)\n",
    "# Ensure Points are included\n",
    "if 'team_points' not in all_stats: \n",
    "    df['home_team_points'] = np.select([df['home_team_score']>df['away_team_score'], df['home_team_score']==df['away_team_score']], [3, 1], 0)\n",
    "    df['away_team_points'] = np.select([df['away_team_score']>df['home_team_score'], df['away_team_score']==df['home_team_score']], [3, 1], 0)\n",
    "    all_stats.append('team_points')\n",
    "\n",
    "print(f\"üîç Detected {len(all_stats)} unique stats (Team + Player).\")\n",
    "\n",
    "# --- 1.3 ROBUST CLEANING (THE FIX) ---\n",
    "print(\"Scrubbing data for artifacts (2*, %, etc)...\")\n",
    "\n",
    "for s in all_stats:\n",
    "    # Handle naming variations (some have 'team_', some don't)\n",
    "    # We construct the list of columns to clean\n",
    "    candidates = []\n",
    "    if f\"home_{s}\" in df.columns: candidates.append(f\"home_{s}\")\n",
    "    if f\"home_team_{s}\" in df.columns: candidates.append(f\"home_team_{s}\")\n",
    "    if f\"away_{s}\" in df.columns: candidates.append(f\"away_{s}\")\n",
    "    if f\"away_team_{s}\" in df.columns: candidates.append(f\"away_team_{s}\")\n",
    "\n",
    "    for col in candidates:\n",
    "        # Regex Clean: Remove non-numeric characters except dots and minus\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].astype(str).str.replace(r'[^\\d\\.-]', '', regex=True)\n",
    "            \n",
    "        # Force Numeric\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        \n",
    "        # Impute\n",
    "        df[col] = df[col].fillna(0) # Simple fill for safety\n",
    "        \n",
    "# ==========================================\n",
    "# 2. FEATURE ENGINEERING\n",
    "# ==========================================\n",
    "\n",
    "# --- ELO ---\n",
    "def calculate_elo(df):\n",
    "    k_factor = 20\n",
    "    home_advantage = 70\n",
    "    team_elos = {team: 1500 for team in set(df['home_team_name']).union(set(df['away_team_name']))}\n",
    "    elo_h, elo_a = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        h, a = row['home_team_name'], row['away_team_name']\n",
    "        rh, ra = team_elos[h], team_elos[a]\n",
    "        elo_h.append(rh); elo_a.append(ra)\n",
    "        if row['home_team_score'] > row['away_team_score']: res = 1\n",
    "        elif row['home_team_score'] == row['away_team_score']: res = 0.5\n",
    "        else: res = 0\n",
    "        dr = (rh + home_advantage) - ra\n",
    "        e_h = 1 / (1 + 10 ** (-dr / 400))\n",
    "        change = k_factor * (res - e_h)\n",
    "        team_elos[h] = rh + change\n",
    "        team_elos[a] = ra - change\n",
    "    return elo_h, elo_a, team_elos\n",
    "\n",
    "df['home_elo'], df['away_elo'], current_elos = calculate_elo(df)\n",
    "df['diff_elo'] = (df['home_elo'] + 70) - df['away_elo']\n",
    "\n",
    "# --- Rolling Stats (ALL FEATURES) ---\n",
    "print(\"Generating Rolling Stats for ALL features...\")\n",
    "h_d = df[['date', 'match_url', 'home_team_name']].rename(columns={'home_team_name':'team'})\n",
    "a_d = df[['date', 'match_url', 'away_team_name']].rename(columns={'away_team_name':'team'})\n",
    "\n",
    "cols_to_roll = []\n",
    "\n",
    "for f in all_stats:\n",
    "    # Resolve names\n",
    "    c_h = f\"home_{f}\" if f\"home_{f}\" in df.columns else f\"home_team_{f}\"\n",
    "    c_a = f\"away_{f}\" if f\"away_{f}\" in df.columns else f\"away_team_{f}\"\n",
    "    \n",
    "    if c_h in df.columns and c_a in df.columns:\n",
    "        h_d[f] = df[c_h]\n",
    "        a_d[f] = df[c_a]\n",
    "        cols_to_roll.append(f)\n",
    "\n",
    "stacked = pd.concat([h_d, a_d]).sort_values(['team', 'date'])\n",
    "\n",
    "# Roll (EWMA 10)\n",
    "for f in cols_to_roll:\n",
    "    # Ensure float\n",
    "    stacked[f] = stacked[f].astype(float)\n",
    "    stacked[f'roll_{f}'] = stacked.groupby('team')[f].transform(lambda x: x.shift(1).ewm(span=10, min_periods=1).mean())\n",
    "\n",
    "# Merge Back\n",
    "rolled_cols = [f'roll_{f}' for f in cols_to_roll]\n",
    "final_stats = stacked[['match_url', 'team'] + rolled_cols]\n",
    "\n",
    "df = df.merge(final_stats, left_on=['match_url', 'home_team_name'], right_on=['match_url', 'team'], how='left')\n",
    "df = df.drop(columns=['team']).rename(columns={c: f\"home_{c}\" for c in rolled_cols})\n",
    "\n",
    "df = df.merge(final_stats, left_on=['match_url', 'away_team_name'], right_on=['match_url', 'team'], how='left')\n",
    "df = df.drop(columns=['team']).rename(columns={c: f\"away_{c}\" for c in rolled_cols})\n",
    "\n",
    "# Differentials\n",
    "for f in cols_to_roll:\n",
    "    h, a = f\"home_roll_{f}\", f\"away_roll_{f}\"\n",
    "    if h in df.columns and a in df.columns:\n",
    "        df[f'diff_{f}'] = df[h] - df[a]\n",
    "\n",
    "df = df.fillna(0)\n",
    "\n",
    "# ==========================================\n",
    "# 3. SELECT FEATURES & PREPARE\n",
    "# ==========================================\n",
    "# Base Features\n",
    "features = [\n",
    "    'diff_elo', 'home_elo', 'away_elo', \n",
    "    'market_prob_home', 'market_prob_draw', 'market_prob_away', 'has_odds'\n",
    "]\n",
    "# Add Rolling & Diffs\n",
    "for f in cols_to_roll:\n",
    "    features.append(f\"home_roll_{f}\")\n",
    "    features.append(f\"away_roll_{f}\")\n",
    "    features.append(f\"diff_{f}\")\n",
    "\n",
    "print(f\"üìä Total Available Features: {len(features)}\")\n",
    "\n",
    "conditions = [\n",
    "    (df['home_team_score'] > df['away_team_score']),\n",
    "    (df['home_team_score'] == df['away_team_score']),\n",
    "    (df['home_team_score'] < df['away_team_score'])\n",
    "]\n",
    "y = np.select(conditions, [2, 1, 0])\n",
    "X = df[features].copy()\n",
    "\n",
    "split = int(len(df) * 0.85)\n",
    "X_train = X.iloc[:split]\n",
    "X_test = X.iloc[split:]\n",
    "y_train = y[:split]\n",
    "y_test = y[split:]\n",
    "\n",
    "# --- FEATURE SELECTION (TOP 60) ---\n",
    "print(\"\\n‚úÇÔ∏è Selecting Top 60 Features (RFECV/ModelBased)...\")\n",
    "selector = SelectFromModel(\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42), \n",
    "    max_features=60, \n",
    "    threshold=-np.inf\n",
    ")\n",
    "selector.fit(X_train, y_train)\n",
    "selected_cols = X_train.columns[selector.get_support()]\n",
    "X_train = X_train[selected_cols]\n",
    "X_test = X_test[selected_cols]\n",
    "print(f\"‚úÖ Reduced to {len(selected_cols)} Features.\")\n",
    "\n",
    "# --- AUGMENTATION (Draw Boosting) ---\n",
    "draw_indices = np.where(y_train == 1)[0]\n",
    "X_train_aug = pd.concat([X_train, X_train.iloc[draw_indices]], axis=0).reset_index(drop=True)\n",
    "y_train_aug = np.concatenate([y_train, y_train[draw_indices]])\n",
    "\n",
    "print(f\"Augmented Train Size: {len(X_train_aug)}\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. TRAINING (VOTING ENSEMBLE)\n",
    "# ==========================================\n",
    "print(\"\\nüèóÔ∏è Building Voting Ensemble...\")\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(n_estimators=300, learning_rate=0.01, max_depth=4, subsample=0.7, objective='multi:softprob', num_class=3, random_state=42)\n",
    "rf_clf = RandomForestClassifier(n_estimators=300, max_depth=12, min_samples_leaf=4, max_features='sqrt', class_weight='balanced', random_state=42)\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[('rf', rf_clf), ('xgb', xgb_clf)],\n",
    "    voting='soft',\n",
    "    weights=[1.5, 1.0] # RF favored\n",
    ")\n",
    "\n",
    "print(\"‚öñÔ∏è Calibrating (Sigmoid)...\")\n",
    "calibrated = CalibratedClassifierCV(ensemble, method='sigmoid', cv=3)\n",
    "calibrated.fit(X_train_aug, y_train_aug)\n",
    "\n",
    "# ==========================================\n",
    "# 5. EVALUATION\n",
    "# ==========================================\n",
    "print(\"\\nüìä EVALUATING...\")\n",
    "preds = calibrated.predict(X_test)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "\n",
    "print(\"==================================================\")\n",
    "print(f\"   FINAL ACCURACY: {acc:.2%}   \")\n",
    "print(\"==================================================\")\n",
    "\n",
    "print(confusion_matrix(y_test, preds))\n",
    "print(classification_report(y_test, preds, target_names=['Away', 'Draw', 'Home']))\n",
    "\n",
    "# Save (Save selected features only!)\n",
    "joblib.dump({\n",
    "    'model': calibrated, \n",
    "    'features': list(selected_cols),\n",
    "    'elo_dict': current_elos,\n",
    "    'df_recent': df[['date', 'home_team_name', 'away_team_name'] + [c for c in df.columns if 'roll_' in c]].tail(1500)\n",
    "}, 'football_model_final.pkl')\n",
    "\n",
    "print(\"‚úÖ Model Saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e47423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "   üîç FEATURE IMPORTANCE (MARKET AWARENESS)       \n",
      "==================================================\n",
      "‚úÖ Model Loaded. Features: 60\n",
      "Error: too many values to unpack (expected 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"==================================================\")\n",
    "print(\"   üîç FEATURE IMPORTANCE (MARKET AWARENESS)       \")\n",
    "print(\"==================================================\")\n",
    "\n",
    "try:\n",
    "    artifacts = joblib.load('football_model_final.pkl')\n",
    "    model = artifacts['model']\n",
    "    features = artifacts['features']\n",
    "    print(f\"‚úÖ Model Loaded. Features: {len(features)}\")\n",
    "    \n",
    "    # Extract from Calibrated -> Voting -> Random Forest (Index 0 or 1 depending on weights)\n",
    "    # Note: VotingClassifier doesn't expose feature_importances_ directly.\n",
    "    # We need to dig into the fitted estimators.\n",
    "    \n",
    "    # 1. Get the Voting Classifier\n",
    "    voting_clf = model.calibrated_classifiers_[0].estimator\n",
    "    \n",
    "    # 2. Get Random Forest (It usually has the best feature importance logic)\n",
    "    # Check names in voting clf\n",
    "    rf_model = voting_clf.named_estimators_.get('rf', None)\n",
    "\n",
    "            \n",
    "    if rf_model:\n",
    "        importances = rf_model.feature_importances_\n",
    "        \n",
    "        # DataFrame\n",
    "        fi_df = pd.DataFrame({\n",
    "            'Feature': features,\n",
    "            'Importance': importances\n",
    "        }).sort_values(by='Importance', ascending=False)\n",
    "        \n",
    "        print(\"\\nüèÜ TOP 20 FEATURES:\")\n",
    "        print(fi_df.head(20).to_string(index=False))\n",
    "        \n",
    "        # Check for Market Odds\n",
    "        print(\"\\nüí∞ MARKET ODDS RANKING:\")\n",
    "        odds_feats = [f for f in features if 'market' in f or 'odds' in f]\n",
    "        print(fi_df[fi_df['Feature'].isin(odds_feats)])\n",
    "        \n",
    "        # Check for Player Stats\n",
    "        print(\"\\nüèÉ NEW PLAYER STATS RANKING (TOP 5):\")\n",
    "        player_feats = [f for f in features if 'player' in f]\n",
    "        print(fi_df[fi_df['Feature'].isin(player_feats)].head(5))\n",
    "\n",
    "    else:\n",
    "        print(\"Could not find Random Forest in ensemble.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bae86a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
