{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f6f509eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "   FOOTBALL MATCH PREDICTOR (GOALS ADDED)         \n",
      "==================================================\n",
      "Training on 1272 matches with 17 features...\n",
      "✅ Enhanced Model Trained (Goals Added).\n",
      "✅ Saved to 'football_model_final.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"==================================================\")\n",
    "print(\"   FOOTBALL MATCH PREDICTOR (GOALS ADDED)         \")\n",
    "print(\"==================================================\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. LOAD & CLEAN DATA\n",
    "# ==========================================\n",
    "try:\n",
    "    df = pd.read_csv(\"match_data.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: match_data.csv not found.\")\n",
    "    exit()\n",
    "\n",
    "def extract_date(url):\n",
    "    try:\n",
    "        match = re.search(r'([A-Za-z]+-\\d{1,2}-\\d{4})', str(url))\n",
    "        if match: return pd.to_datetime(match.group(1), format='%B-%d-%Y', errors='coerce')\n",
    "    except: pass\n",
    "    return pd.NaT\n",
    "\n",
    "df['date'] = df['match_url'].apply(extract_date)\n",
    "df = df.sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "# Numeric Cleaning\n",
    "stats_cols = [\"xg\", \"possession\", \"shots_onTarget\", \"corners\", \"fouls\", \"team_points\"]\n",
    "for side in ['home', 'away']:\n",
    "    p_col = f\"{side}_team_possession\"\n",
    "    if p_col in df.columns:\n",
    "        df[p_col] = pd.to_numeric(df[p_col].astype(str).str.rstrip('%'), errors='coerce').fillna(50) / 100.0\n",
    "    \n",
    "    for s in stats_cols:\n",
    "        col = f\"{side}_{s}\" if s not in ['xg', 'possession', 'team_points'] else f\"{side}_team_{s}\"\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            df[col] = df[col].fillna(df.groupby(f'{side}_team_name')[col].transform('median'))\n",
    "            df[col] = df[col].fillna(df[col].mean())\n",
    "\n",
    "# ==========================================\n",
    "# 2. FEATURE ENGINEERING ENGINE\n",
    "# ==========================================\n",
    "\n",
    "# --- ELO (Standard +70 Home) ---\n",
    "def calculate_elo(df):\n",
    "    k_factor = 20\n",
    "    home_advantage = 70\n",
    "    team_elos = {team: 1500 for team in set(df['home_team_name']).union(set(df['away_team_name']))}\n",
    "    elo_h, elo_a = [], []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        h, a = row['home_team_name'], row['away_team_name']\n",
    "        rh, ra = team_elos[h], team_elos[a]\n",
    "        elo_h.append(rh); elo_a.append(ra)\n",
    "        \n",
    "        if row['home_team_score'] > row['away_team_score']: res = 1\n",
    "        elif row['home_team_score'] == row['away_team_score']: res = 0.5\n",
    "        else: res = 0\n",
    "        \n",
    "        dr = (rh + home_advantage) - ra\n",
    "        e_h = 1 / (1 + 10 ** (-dr / 400))\n",
    "        \n",
    "        change = k_factor * (res - e_h)\n",
    "        team_elos[h] = rh + change\n",
    "        team_elos[a] = ra - change\n",
    "        \n",
    "    return elo_h, elo_a, team_elos\n",
    "\n",
    "df['home_elo'], df['away_elo'], current_elos = calculate_elo(df)\n",
    "df['diff_elo'] = (df['home_elo'] + 70) - df['away_elo']\n",
    "\n",
    "# --- Rest Days ---\n",
    "long_df = pd.concat([\n",
    "    df[['date', 'home_team_name']].rename(columns={'home_team_name':'team'}),\n",
    "    df[['date', 'away_team_name']].rename(columns={'away_team_name':'team'})\n",
    "]).sort_values(['team', 'date'])\n",
    "long_df['rest'] = (long_df['date'] - long_df.groupby('team')['date'].shift(1)).dt.days.fillna(7).clip(upper=14)\n",
    "rest_map = dict(zip(zip(long_df['date'], long_df['team']), long_df['rest']))\n",
    "\n",
    "df['diff_rest'] = df.apply(lambda x: rest_map.get((x['date'], x['home_team_name']),7), axis=1) - \\\n",
    "                  df.apply(lambda x: rest_map.get((x['date'], x['away_team_name']),7), axis=1)\n",
    "\n",
    "# --- NEW: GOALS & CONCEDED COLUMNS ---\n",
    "# We need to explicitly calculate what each team scored and conceded to roll it\n",
    "df['home_goals_scored'] = df['home_team_score']\n",
    "df['home_goals_conceded'] = df['away_team_score']\n",
    "df['away_goals_scored'] = df['away_team_score']\n",
    "df['away_goals_conceded'] = df['home_team_score']\n",
    "\n",
    "# --- Rolling Stats (EWMA) ---\n",
    "df['home_team_points'] = np.select([df['home_team_score']>df['away_team_score'], df['home_team_score']==df['away_team_score']], [3, 1], 0)\n",
    "df['away_team_points'] = np.select([df['away_team_score']>df['home_team_score'], df['away_team_score']==df['home_team_score']], [3, 1], 0)\n",
    "\n",
    "# ADDED: 'goals_scored', 'goals_conceded'\n",
    "roll_feats = ['team_xg', 'team_possession', 'shots_onTarget', 'corners', 'team_points', 'fouls', 'goals_scored', 'goals_conceded']\n",
    "\n",
    "h_d = df[['date', 'match_url', 'home_team_name']].rename(columns={'home_team_name':'team'})\n",
    "a_d = df[['date', 'match_url', 'away_team_name']].rename(columns={'away_team_name':'team'})\n",
    "\n",
    "for f in roll_feats:\n",
    "    # Logic to find the right column name in the source DF\n",
    "    if f in ['goals_scored', 'goals_conceded']:\n",
    "        col_h, col_a = f\"home_{f}\", f\"away_{f}\"\n",
    "    elif f in ['team_points', 'team_xg', 'team_possession']:\n",
    "        col_h, col_a = f\"home_{f}\", f\"away_{f}\"\n",
    "    else:\n",
    "        col_h, col_a = f\"home_{f}\", f\"away_{f}\"\n",
    "        \n",
    "    if col_h in df.columns: h_d[f] = df[col_h]\n",
    "    if col_a in df.columns: a_d[f] = df[col_a]\n",
    "\n",
    "stacked = pd.concat([h_d, a_d]).sort_values(['team', 'date'])\n",
    "\n",
    "for f in roll_feats:\n",
    "    if f in stacked.columns:\n",
    "        # EWMA Span 10 (Longer term view helps stability)\n",
    "        stacked[f'roll_{f}'] = stacked.groupby('team')[f].transform(lambda x: x.shift(1).ewm(span=10, min_periods=1).mean())\n",
    "\n",
    "df = df.merge(stacked[['match_url', 'team'] + [f'roll_{f}' for f in roll_feats]], left_on=['match_url', 'home_team_name'], right_on=['match_url', 'team'], how='left').drop(columns=['team']).rename(columns={f'roll_{f}': f'home_roll_{f}' for f in roll_feats})\n",
    "df = df.merge(stacked[['match_url', 'team'] + [f'roll_{f}' for f in roll_feats]], left_on=['match_url', 'away_team_name'], right_on=['match_url', 'team'], how='left').drop(columns=['team']).rename(columns={f'roll_{f}': f'away_roll_{f}' for f in roll_feats})\n",
    "\n",
    "for f in roll_feats:\n",
    "    df[f'diff_{f}'] = df[f'home_roll_{f}'] - df[f'away_roll_{f}']\n",
    "\n",
    "df = df.fillna(0)\n",
    "\n",
    "# ==========================================\n",
    "# 3. MODEL CONFIGURATION\n",
    "# ==========================================\n",
    "features = [\n",
    "    'diff_elo', 'home_elo', 'away_elo',\n",
    "    'diff_rest', 'diff_team_points', \n",
    "    'diff_team_xg', 'diff_team_possession', \n",
    "    'diff_shots_onTarget', 'diff_corners',\n",
    "    # NEW DIFFS\n",
    "    'diff_goals_scored', 'diff_goals_conceded', \n",
    "    \n",
    "    # Raw Rolling Context\n",
    "    'home_roll_team_xg', 'away_roll_team_xg',\n",
    "    'home_roll_goals_scored', 'away_roll_goals_scored', # Crucial for \"Can they finish?\"\n",
    "    'home_roll_goals_conceded', 'away_roll_goals_conceded' # Crucial for \"Is defense leaky?\"\n",
    "]\n",
    "\n",
    "conditions = [\n",
    "    (df['home_team_score'] > df['away_team_score']),\n",
    "    (df['home_team_score'] == df['away_team_score']),\n",
    "    (df['home_team_score'] < df['away_team_score'])\n",
    "]\n",
    "y = np.select(conditions, [2, 1, 0])\n",
    "X = df[features]\n",
    "\n",
    "print(f\"Training on {len(X)} matches with {len(features)} features...\")\n",
    "\n",
    "# --- Stacking Ensemble ---\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    n_estimators=300, learning_rate=0.01, max_depth=3, \n",
    "    subsample=0.7, colsample_bytree=0.8, gamma=3, # Slightly reduced gamma\n",
    "    objective='multi:softprob', num_class=3, random_state=42\n",
    ")\n",
    "\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=200, max_depth=8, min_samples_leaf=3, \n",
    "    max_features=0.5, random_state=42\n",
    ")\n",
    "\n",
    "lr_clf = make_pipeline(StandardScaler(), LogisticRegression(C=0.1, solver='lbfgs', multi_class='multinomial', max_iter=1000))\n",
    "\n",
    "stacking_ensemble = StackingClassifier(\n",
    "    estimators=[('xgb', xgb_clf), ('rf', rf_clf), ('lr', lr_clf)],\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "calibrated = CalibratedClassifierCV(stacking_ensemble, method='isotonic', cv=3)\n",
    "calibrated.fit(X, y)\n",
    "\n",
    "print(\"✅ Enhanced Model Trained (Goals Added).\")\n",
    "\n",
    "# Save\n",
    "joblib.dump({\n",
    "    'model': calibrated, \n",
    "    'features': features,\n",
    "    'elo_dict': current_elos,\n",
    "    'df_recent': df[['date', 'home_team_name', 'away_team_name'] + [c for c in df.columns if 'roll_' in c]].tail(1000)\n",
    "}, 'football_model_final.pkl')\n",
    "\n",
    "print(\"✅ Saved to 'football_model_final.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c038fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "   CALIBRATED ACCURACY: 60.00%   \n",
      "==================================================\n",
      "Sample Probabilities (First 5 matches):\n",
      "[[0.13950142 0.25849408 0.6020045 ]\n",
      " [0.52919244 0.20402902 0.26677854]\n",
      " [0.47610285 0.21800867 0.30588848]\n",
      " [0.1257092  0.20255163 0.67173916]\n",
      " [0.20530875 0.21450411 0.58018714]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(probs[:\u001b[32m5\u001b[39m])\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Value Bets Check\u001b[39;00m\n\u001b[32m     24\u001b[39m results = pd.DataFrame({\n\u001b[32m     25\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mHome\u001b[39m\u001b[33m'\u001b[39m: df.iloc[split:][\u001b[33m'\u001b[39m\u001b[33mhome_team_name\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     26\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mAway\u001b[39m\u001b[33m'\u001b[39m: df.iloc[split:][\u001b[33m'\u001b[39m\u001b[33maway_team_name\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mActual\u001b[39m\u001b[33m'\u001b[39m: \u001b[43my_test\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m,\n\u001b[32m     28\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mPred\u001b[39m\u001b[33m'\u001b[39m: preds,\n\u001b[32m     29\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mConf\u001b[39m\u001b[33m'\u001b[39m: np.max(probs, axis=\u001b[32m1\u001b[39m)\n\u001b[32m     30\u001b[39m })\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m [\u001b[32m0.45\u001b[39m, \u001b[32m0.50\u001b[39m, \u001b[32m0.60\u001b[39m, \u001b[32m0.70\u001b[39m, \u001b[32m0.80\u001b[39m]:\n\u001b[32m     33\u001b[39m     sub = results[results[\u001b[33m'\u001b[39m\u001b[33mConf\u001b[39m\u001b[33m'\u001b[39m] > t]\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "split = int(len(X) * 0.8)\n",
    "X_train, y_train = X[:split], y[:split]\n",
    "X_test, y_test = X[split:], y[split:]\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 7. FINAL EVALUATION\n",
    "# ==========================================\n",
    "preds = calibrated.predict(X_test)\n",
    "probs = calibrated.predict_proba(X_test)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "\n",
    "print(\"==================================================\")\n",
    "print(f\"   CALIBRATED ACCURACY: {acc:.2%}   \")\n",
    "print(\"==================================================\")\n",
    "\n",
    "# Check the new Probabilities\n",
    "print(\"Sample Probabilities (First 5 matches):\")\n",
    "print(probs[:5])\n",
    "\n",
    "# Value Bets Check\n",
    "results = pd.DataFrame({\n",
    "    'Home': df.iloc[split:]['home_team_name'],\n",
    "    'Away': df.iloc[split:]['away_team_name'],\n",
    "    'Actual': y_test,\n",
    "    'Pred': preds,\n",
    "    'Conf': np.max(probs, axis=1)\n",
    "})\n",
    "\n",
    "for t in [0.45, 0.50, 0.60, 0.70, 0.80]:\n",
    "    sub = results[results['Conf'] > t]\n",
    "    if len(sub) > 0:\n",
    "        print(f\"Threshold > {t:.2f}: {len(sub)} matches | Accuracy: {accuracy_score(sub['Actual'], sub['Pred']):.2%}\")\n",
    "\n",
    "# Save the CALIBRATED model\n",
    "joblib.dump({\n",
    "    'model': calibrated, \n",
    "    'features': features,\n",
    "    'elo_dict': dict(zip(df['home_team_name'], df['home_elo'])),\n",
    "    'df_recent': df[['date', 'home_team_name', 'away_team_name'] + [c for c in df.columns if 'roll_' in c]].tail(1000)\n",
    "}, 'football_model_final.pkl')\n",
    "\n",
    "print(\"✅ Calibrated Model saved.\")\n",
    "\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "print(cm)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, preds):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4272f50e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
