{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f509eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import re\n",
    "import warnings\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"==================================================\")\n",
    "print(\"   HYPERPARAMETER TUNING ENGINE (ELO + ENSEMBLE)  \")\n",
    "print(\"==================================================\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. LOAD & CLEAN (Same Feature Engineering)\n",
    "# ==========================================\n",
    "# We must recreate the exact features (ELO, Rolling, Rest) first\n",
    "df = pd.read_csv(\"match_data.csv\")\n",
    "\n",
    "def extract_date(url):\n",
    "    try:\n",
    "        match = re.search(r'([A-Za-z]+-\\d{1,2}-\\d{4})', str(url))\n",
    "        if match: return pd.to_datetime(match.group(1), format='%B-%d-%Y', errors='coerce')\n",
    "    except: pass\n",
    "    return pd.NaT\n",
    "\n",
    "df['date'] = df['match_url'].apply(extract_date)\n",
    "df = df.sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "# Basic Numeric Cleaning & Imputation\n",
    "stats_cols = [\"xg\", \"possession\", \"shots_onTarget\", \"corners\", \"fouls\", \"team_points\"]\n",
    "for side in ['home', 'away']:\n",
    "    p_col = f\"{side}_team_possession\"\n",
    "    if p_col in df.columns:\n",
    "        df[p_col] = pd.to_numeric(df[p_col].astype(str).str.rstrip('%'), errors='coerce').fillna(50) / 100.0\n",
    "    \n",
    "    # Calculate points if missing (3 for win logic)\n",
    "    if 'team_points' not in df.columns and f'{side}_team_score' in df.columns:\n",
    "        # (Logic handled in rolling block below)\n",
    "        pass\n",
    "\n",
    "    for s in stats_cols:\n",
    "        col = f\"{side}_{s}\" if s not in ['xg', 'possession', 'team_points'] else f\"{side}_team_{s}\"\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            # Group median fill\n",
    "            df[col] = df[col].fillna(df.groupby(f'{side}_team_name')[col].transform('median'))\n",
    "            df[col] = df[col].fillna(df[col].mean()) # Fallback\n",
    "\n",
    "# --- ELO CALCULATION ---\n",
    "def calculate_elo(df):\n",
    "    k_factor = 20\n",
    "    home_advantage = 65 # Lowered slightly for modern football\n",
    "    team_elos = {team: 1500 for team in set(df['home_team_name']).union(set(df['away_team_name']))}\n",
    "    elo_h, elo_a = [], []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        h, a = row['home_team_name'], row['away_team_name']\n",
    "        rh, ra = team_elos[h], team_elos[a]\n",
    "        elo_h.append(rh); elo_a.append(ra)\n",
    "        \n",
    "        if row['home_team_score'] > row['away_team_score']: res = 1\n",
    "        elif row['home_team_score'] == row['away_team_score']: res = 0.5\n",
    "        else: res = 0\n",
    "        \n",
    "        dr = (rh + home_advantage) - ra\n",
    "        e_h = 1 / (1 + 10 ** (-dr / 400))\n",
    "        team_elos[h] = rh + k_factor * (res - e_h)\n",
    "        team_elos[a] = ra + k_factor * ((1 - res) - (1 - e_h))\n",
    "        \n",
    "    return elo_h, elo_a\n",
    "\n",
    "df['home_elo'], df['away_elo'] = calculate_elo(df)\n",
    "df['diff_elo'] = (df['home_elo'] + 65) - df['away_elo']\n",
    "\n",
    "# --- REST DAYS ---\n",
    "def calc_rest(df):\n",
    "    long_df = pd.concat([\n",
    "        df[['date', 'home_team_name']].rename(columns={'home_team_name':'team'}),\n",
    "        df[['date', 'away_team_name']].rename(columns={'away_team_name':'team'})\n",
    "    ]).sort_values(['team', 'date'])\n",
    "    long_df['rest'] = (long_df['date'] - long_df.groupby('team')['date'].shift(1)).dt.days.fillna(7).clip(upper=14)\n",
    "    return dict(zip(zip(long_df['date'], long_df['team']), long_df['rest']))\n",
    "\n",
    "rest_map = calc_rest(df)\n",
    "df['diff_rest'] = df.apply(lambda x: rest_map.get((x['date'], x['home_team_name']),7), axis=1) - \\\n",
    "                  df.apply(lambda x: rest_map.get((x['date'], x['away_team_name']),7), axis=1)\n",
    "\n",
    "# --- ROLLING STATS ---\n",
    "# Recalculate points specifically for rolling\n",
    "df['home_team_points'] = np.select([df['home_team_score']>df['away_team_score'], df['home_team_score']==df['away_team_score']], [3, 1], 0)\n",
    "df['away_team_points'] = np.select([df['away_team_score']>df['home_team_score'], df['away_team_score']==df['home_team_score']], [3, 1], 0)\n",
    "\n",
    "roll_feats = ['team_xg', 'team_possession', 'shots_onTarget', 'corners', 'team_points']\n",
    "h_d = df[['date', 'match_url', 'home_team_name']].rename(columns={'home_team_name':'team'})\n",
    "a_d = df[['date', 'match_url', 'away_team_name']].rename(columns={'away_team_name':'team'})\n",
    "\n",
    "for f in roll_feats:\n",
    "    c_h = f\"home_{f}\" if f in ['team_points', 'team_xg', 'team_possession'] else f\"home_{f}\"\n",
    "    c_a = f\"away_{f}\" if f in ['team_points', 'team_xg', 'team_possession'] else f\"away_{f}\"\n",
    "    if c_h in df.columns: h_d[f] = df[c_h]\n",
    "    if c_a in df.columns: a_d[f] = df[c_a]\n",
    "\n",
    "stacked = pd.concat([h_d, a_d]).sort_values(['team', 'date'])\n",
    "for f in roll_feats:\n",
    "    if f in stacked.columns:\n",
    "        stacked[f'roll_{f}'] = stacked.groupby('team')[f].transform(lambda x: x.shift(1).rolling(5, min_periods=1).mean())\n",
    "\n",
    "df = df.merge(stacked[['match_url', 'team'] + [f'roll_{f}' for f in roll_feats]], left_on=['match_url', 'home_team_name'], right_on=['match_url', 'team'], how='left').drop(columns=['team']).rename(columns={f'roll_{f}': f'home_roll_{f}' for f in roll_feats})\n",
    "df = df.merge(stacked[['match_url', 'team'] + [f'roll_{f}' for f in roll_feats]], left_on=['match_url', 'away_team_name'], right_on=['match_url', 'team'], how='left').drop(columns=['team']).rename(columns={f'roll_{f}': f'away_roll_{f}' for f in roll_feats})\n",
    "\n",
    "for f in roll_feats:\n",
    "    df[f'diff_{f}'] = df[f'home_roll_{f}'] - df[f'away_roll_{f}']\n",
    "\n",
    "df = df.fillna(0)\n",
    "\n",
    "# ==========================================\n",
    "# 2. PREPARE FOR TUNING\n",
    "# ==========================================\n",
    "conditions = [\n",
    "    (df['home_team_score'] > df['away_team_score']),\n",
    "    (df['home_team_score'] == df['away_team_score']),\n",
    "    (df['home_team_score'] < df['away_team_score'])\n",
    "]\n",
    "df['match_outcome'] = np.select(conditions, [2, 1, 0])\n",
    "\n",
    "features = [\n",
    "    'diff_elo', 'home_elo', 'away_elo',\n",
    "    'diff_rest', 'diff_team_points', 'diff_team_xg', \n",
    "    'diff_shots_onTarget', 'diff_corners',\n",
    "    'home_roll_team_xg', 'away_roll_team_xg'\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df['match_outcome']\n",
    "\n",
    "# Time Series Split (Crucial for validity)\n",
    "# 4 splits = Test on last 20%, then last 40%, etc.\n",
    "tscv = TimeSeriesSplit(n_splits=4)\n",
    "\n",
    "print(f\"Tuning on {len(X)} matches...\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. TUNE XGBOOST\n",
    "# ==========================================\n",
    "print(\"\\n--- Tuning XGBoost ---\")\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.03, 0.05],\n",
    "    'max_depth': [3, 4],\n",
    "    'subsample': [0.7, 0.8],\n",
    "    'colsample_bytree': [0.7, 0.8],\n",
    "    'gamma': [1, 5] # Regularization\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softprob', num_class=3, tree_method='hist', random_state=42)\n",
    "xgb_search = GridSearchCV(xgb_model, xgb_param_grid, cv=tscv, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "xgb_search.fit(X, y)\n",
    "\n",
    "print(f\"✅ Best XGB Params: {xgb_search.best_params_}\")\n",
    "print(f\"✅ Best XGB Score: {xgb_search.best_score_:.2%}\")\n",
    "best_xgb = xgb_search.best_estimator_\n",
    "\n",
    "# ==========================================\n",
    "# 4. TUNE RANDOM FOREST\n",
    "# ==========================================\n",
    "print(\"\\n--- Tuning Random Forest ---\")\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [200, 400],\n",
    "    'max_depth': [5, 8, 10], # Keep shallow to prevent overfitting noise\n",
    "    'min_samples_leaf': [3, 5, 10], # Higher = more generalized\n",
    "    'max_features': ['sqrt', 0.5]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_search = GridSearchCV(rf_model, rf_param_grid, cv=tscv, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "rf_search.fit(X, y)\n",
    "\n",
    "print(f\"✅ Best RF Params: {rf_search.best_params_}\")\n",
    "print(f\"✅ Best RF Score: {rf_search.best_score_:.2%}\")\n",
    "best_rf = rf_search.best_estimator_\n",
    "\n",
    "# ==========================================\n",
    "# 5. TUNE LOGISTIC REGRESSION\n",
    "# ==========================================\n",
    "print(\"\\n--- Tuning Logistic Regression ---\")\n",
    "lr_param_grid = {\n",
    "    'C': [0.01, 0.1, 1.0, 10.0], # Regularization strength\n",
    "    'solver': ['lbfgs', 'newton-cg']\n",
    "}\n",
    "\n",
    "scaler = StandardScaler() # LR needs scaled data\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "lr_model = LogisticRegression(multi_class='multinomial', max_iter=2000)\n",
    "lr_search = GridSearchCV(lr_model, lr_param_grid, cv=tscv, scoring='accuracy', n_jobs=-1)\n",
    "lr_search.fit(X_scaled, y)\n",
    "\n",
    "print(f\"✅ Best LR Params: {lr_search.best_params_}\")\n",
    "print(f\"✅ Best LR Score: {lr_search.best_score_:.2%}\")\n",
    "best_lr = lr_search.best_estimator_\n",
    "\n",
    "# ==========================================\n",
    "# 6. BUILD FINAL ENSEMBLE\n",
    "# ==========================================\n",
    "print(\"\\n--- Training Final Ensemble ---\")\n",
    "\n",
    "# We retrain the best models on the FULL dataset (minus the very last test chunk for final verification)\n",
    "split = int(len(X) * 0.90)\n",
    "X_train, X_test = X.iloc[:split], X.iloc[split:]\n",
    "y_train, y_test = y.iloc[:split], y.iloc[split:]\n",
    "\n",
    "# Note: LR needs scaling pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe_lr = make_pipeline(StandardScaler(), best_lr)\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', best_xgb),\n",
    "        ('rf', best_rf),\n",
    "        ('lr', pipe_lr)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    # Weight based on validation scores. \n",
    "    # Usually XGB > LR > RF for this data size.\n",
    "    weights=[3, 1, 2] \n",
    ")\n",
    "\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "# ==========================================\n",
    "# 7. FINAL EVALUATION\n",
    "# ==========================================\n",
    "preds = ensemble.predict(X_test)\n",
    "probs = ensemble.predict_proba(X_test)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "\n",
    "print(\"==================================================\")\n",
    "print(f\"   TUNED ENSEMBLE ACCURACY: {acc:.2%}   \")\n",
    "print(\"==================================================\")\n",
    "\n",
    "# Value Bets Check\n",
    "results = pd.DataFrame({\n",
    "    'Home': df.iloc[split:]['home_team_name'],\n",
    "    'Away': df.iloc[split:]['away_team_name'],\n",
    "    'Actual': y_test.values,\n",
    "    'Pred': preds,\n",
    "    'Conf': np.max(probs, axis=1)\n",
    "})\n",
    "\n",
    "for t in [0.45, 0.50, 0.60]:\n",
    "    sub = results[results['Conf'] > t]\n",
    "    if len(sub) > 0:\n",
    "        print(f\"Threshold > {t:.2f}: {len(sub)} matches | Accuracy: {accuracy_score(sub['Actual'], sub['Pred']):.2%}\")\n",
    "\n",
    "# Save Everything\n",
    "joblib.dump({\n",
    "    'model': ensemble, \n",
    "    'features': features, \n",
    "    'scaler': scaler,\n",
    "    'elo_dict': dict(zip(df['home_team_name'], df['home_elo'])) # Save latest ELOs\n",
    "}, 'tuned_ensemble_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
